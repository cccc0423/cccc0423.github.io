<!DOCTYPE html>
<html lang="">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>週記（三十三）</title>
    <meta name="description" content="渾渾噩噩的一週">
    <meta name="author" content="cccc0423">
    <meta name="robots" content="index, follow">
    
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>

    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.11.1/styles/default.min.css">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.11.1/highlight.min.js"></script>

    <!-- and it's easy to individually load additional languages -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.11.1/languages/go.min.js"></script>

    <script>hljs.highlightAll();</script>
    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.7.2/css/all.min.css" integrity="sha512-Evv84Mr4kqVGRNSgIGL/F/aIDqQb7xQ2vcrdIwxfjThSH8CSR7PBEakCr51Ck+w+/U6swU2Im1vVX0SVk9ABhg==" crossorigin="anonymous" referrerpolicy="no-referrer" />
    <link rel="stylesheet" href="../css/style.css">
    <link href="https://fonts.googleapis.com/icon?family=Material+Icons" rel="stylesheet">

    <script>
        MathJax = {
            loader: {load: ['[tex]/mathtools']},
            tex: {packages: {'[+]': ['mathtools']}}
        };
    </script>
    <script>
        MathJax = {
            loader: {load: ['[tex]/textmacros']},
            tex: {packages: {'[+]': ['textmacros']}}
        };
    </script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

    <script src="../js/main.js" defer></script>
    
    <link rel="canonical" href="https://cccc0423.github.io/weekly/20250906-weekly-writing.html" />
</head>
<button id="back-to-top" class="fab fab-scroll" aria-label="back-to-top">
    <span class="material-icons">arrow_upward</span>
</button>
<body>
    <header>
        <div class="navbar">
            <a href="../index.html" class="nav-brand">小學生筆記</a>
            <button class="hamburger-menu" aria-label="Toggle menu">
                <span></span>
                <span></span>
                <span></span>
            </button>
            <div class="nav-links">
                <a href="../weekly.html" class="active">週記</a>
                <a href="../about.html" class="">關於</a>
            </div>
        </div>
    </header>

    <main>
        <h1>週記（三十三）</h1>
        <p class="post-date">2025-09-06</p>

                <div class="toc">
            <h2>Table of Contents</h2>
            <ul>
            <li><a href="#什麼是自由教育"
            id="toc-什麼是自由教育">什麼是自由教育？</a></li>
            <li><a href="#簡單隨機抽樣"
            id="toc-簡單隨機抽樣">簡單隨機抽樣</a></li>
            </ul>
        </div>
        
        <h2 id="什麼是自由教育">什麼是自由教育？</h2>
        <p>有一天在研究室， 同學們談到一些價值觀或人生觀的問題，
        包括未來期待怎樣的職涯， 或者更喜歡怎樣的哲學家等等的問題。</p>
        <p>與這有點相關但又不太相關的是， 我想到我高中時讀過的一篇文章，
        Leo Strauss 的〈什麼是自由教育？〉（What Is Liberal
        Education?）。</p>
        <p>Strauss 首先提出自由教育的定義：在文化之中或朝向文化的教育。
        文化（culture）這個字來自拉丁文的 cultura，
        最初的意思是耕作（cultivation），
        即按照土壤的本性來改良土壤、培育作物。
        後來這個字的意思擴展到人類的精神生活， 即對心靈的培育。
        因此，自由教育按照人的心靈的本性來培育人內在的能力。
        但正如土壤需要農夫， 心靈也需要老師，
        也就是那些「最偉大的心靈」。 這些「最偉大的心靈」極為罕見，
        學生主要透過「偉大的書籍」接觸他們。 因此，自由教育需要以
        「適當的態度研讀那些最偉大的心靈所留下的著作」。</p>
        <p>這時 Strauss
        話鋒一轉，追問自由教育在現代民主社會中的意義為何？
        最初，民主制被期待為一種德性的政體， 一種普遍的貴族制度，
        而適用於一個多數人都擁有高度理性的社會。
        但正如盧梭在《社會契約論》中的質疑
        「如果有一個由神組成的民族，它就會民主地治理自己。如此完美的政府不適合人類。」
        Strauss 更指出現代民主並非大眾統治， 而僅是大眾文化，
        而這種文化「可以被最平庸的能力在無需任何智力與道德努力下，以非常低的金錢代價獲取」。
        大眾文化創造出韋伯所謂「沒有精神或睿智的專家與沒有良心的享樂主義者」，
        而自由教育即是大眾文化的解毒劑， 抵抗大眾文化的侵蝕。
        自由教育可以說是從大眾民主到古典意義中的民主的階梯。
        因此，他又形容自由教育是要喚醒人自身的卓越。</p>
        <p>那麼，自由教育如何喚醒人自身的卓越呢？ 如同柏拉圖說的，
        最好的教育是哲學。
        這是因為，哲學對最重要的、最高的或最全面事物的智慧或知識的追求。
        雖然我們不能成為哲學家 （就連 Strauss
        自己也不認為自己是哲學家，而是個學者）， 但我們可以愛哲學，
        聆聽偉大哲學家，乃至於最偉大的心靈之間的對話，
        也就是閱讀偉大的書籍。
        他最後又強調，自由教育是對謙遜、大膽的訓練，
        目的是讓我們從是從庸俗（apeirokalia）中解放出來。</p>
        <h2 id="簡單隨機抽樣">簡單隨機抽樣</h2>
        <p>假設我們有一個有限母體，包含 <span
        class="math inline">\(n\)</span> 個個體。 一個大小為 <span
        class="math inline">\(n_1\)</span> 的簡單隨機樣本 （simple
        random sample, SRS）是從母體中不放回地抽出 <span
        class="math inline">\(n_1\)</span> 個個體。 令 <span
        class="math inline">\(\mathbf{Z} = (Z_1, \ldots, Z_n)\)</span>
        是一個指標向量， 而 <span class="math inline">\(Z_i = 1\)</span>
        表示個體 <span class="math inline">\(i\)</span>
        被抽到，反之則表示沒被抽到。</p>
        <p>在 SRS 下， SRS 可能包含 <span
        class="math inline">\(\binom{n}{n_1}\)</span>
        種可能的排列（permutations）， 其中有 <span
        class="math inline">\(n_1\)</span> 個 <span
        class="math inline">\(1\)</span> 與 <span
        class="math inline">\(n - n_1\)</span> 個 <span
        class="math inline">\(0\)</span>， 而每一種排列的機率都是 <span
        class="math inline">\(\pi = 1 / \binom{n}{n_1}\)</span>。</p>
        <p>在 SRS 下，我們可以計算</p>
        <ol type="1">
        <li><p><span class="math inline">\(\operatorname{E}(Z_i) = n_1 /
        n\)</span>；</p></li>
        <li><p><span class="math inline">\(\operatorname{Var}(Z_i) =
        \frac{n_1 n_0}{n^2}\)</span>；</p></li>
        <li><p><span class="math inline">\(\operatorname{Cov}(Z_i, Z_j)
        = -\frac{n_1 n_0}{n^2 (n - 1)}\)</span>，其中 <span
        class="math inline">\(i \neq j\)</span>。</p></li>
        </ol>
        <p>首先，<span class="math inline">\(\operatorname{E}(Z_i) =
        P(Z_i = 1)\)</span>， 即從 <span
        class="math inline">\(n\)</span> 個個體中抽出 <span
        class="math inline">\(n_1\)</span> 個樣本且個體 <span
        class="math inline">\(i\)</span> 被抽到的機率，因此 <span
        class="math display">\[
        \operatorname{E}(Z_i) = \frac{\binom{n - 1}{n_1 -
        1}}{\binom{n}{n}} = \frac{n_1}{n}.
        \]</span> 再來，因為 <span class="math inline">\(Z_i \sim
        \operatorname{Bernoulli}\left(\frac{n_1}{n}\right)\)</span>，
        所以 <span class="math display">\[
        \operatorname{Var}(Z_i)
        = \frac{n_1}{n}\left(1 - \frac{n_1}{n}\right)
        = \frac{n_1 n_0}{n^2}.
        \]</span> 最後，我們知道 <span
        class="math inline">\(\operatorname{E}(Z_iZ_j) = P(Z_i = 1, Z_j
        = 1)\)</span>， 即從 <span class="math inline">\(n\)</span>
        個個體中抽出 <span class="math inline">\(n_1\)</span>
        個樣本且個體 <span class="math inline">\(i\)</span> 和 <span
        class="math inline">\(j\)</span> 都被抽到的機率， 因此 <span
        class="math display">\[
        \operatorname{E}(Z_i Z_j)
        = \frac{\binom{n - 2}{n_1 - 2}}{\binom{n}{n_1}}
        = \frac{n_1 (n_1 - 1)}{n(n - 1)},
        \]</span> 而 <span class="math display">\[
        \operatorname{Cov}(Z_i, Z_j)
        = \frac{n_1(n_1 - 1)}{n(n - 1)} - \frac{n_1^2}{n^2}
        = -\frac{n_1 n_0}{n^2(n - 1)}.
        \]</span> 如此證畢。</p>
        <p>我們也可以把以上的關係寫成向量、矩陣的形式。 定義投影矩陣
        <span class="math inline">\(\mathbf{P}_n \equiv \mathbf{I}_n -
        \frac{1}{n} \mathbf{1}_n
        \mathbf{1}_n^\intercal\)</span>， 其中 <span
        class="math inline">\(\mathbf{I}_n\)</span> 是 <span
        class="math inline">\(n \times n\)</span> 的單位矩陣， 而 <span
        class="math inline">\(\mathbf{1}_n\)</span> 是 <span
        class="math inline">\(n \times 1\)</span> 的行向量，全部元素都是
        <span class="math inline">\(1\)</span>。 對於任何向量， 投影矩陣
        <span class="math inline">\(\mathbf{P}_n\)</span>
        都能將它投影到與 <span
        class="math inline">\(\mathbf{1}_n\)</span> 正交的子空間。
        而我們有 <span class="math display">\[
        \begin{aligned}
        \operatorname{E}(\mathbf{Z}) &amp;= \frac{n_1}{n} \mathbf{1}_n,
        \\
        \operatorname{Cov}(\mathbf{Z}) &amp;= \frac{n_1 n_0}{n(n - 1)}
        \mathbf{P}_n.
        \end{aligned}
        \]</span></p>
        <p>這樣看來， 要計算期望值、變異數和共變異數，
        也從幾何（？）的視角切入。 令 <span
        class="math inline">\(\sigma: \{1, \ldots, n\} \to \{1, \ldots,
        n\}\)</span> 是一個排列（permutation）， <span
        class="math inline">\(\mathbf{Q}_{\sigma}\)</span>
        是一個排列矩陣（permutation matrix）， 定義成 <span
        class="math display">\[
        (\mathbf{Q}_{\sigma})_{ij} =
        \begin{cases}
        1, &amp; \text{if } i = \sigma(j), \\
        0, &amp; \text{otherwise}.
        \end{cases}
        \]</span> 這個矩陣 <span
        class="math inline">\(\mathbf{Q}_{\sigma}\)</span>
        的每行和每列都有且只有一個 <span
        class="math inline">\(1\)</span>， 故顯然它是一個正交矩陣，
        <span class="math inline">\(\mathbf{Q}_{\sigma}^\intercal =
        \mathbf{Q}_{\sigma}^{-1}\)</span>。 令 <span
        class="math inline">\(\mathcal{S}\)</span> 是所有可能的樣本組合
        即 <span class="math display">\[
        \mathcal{S} = \{z \in \{0, 1\}^n : \mathbf{1}_n^\intercal z =
        n_1\}.
        \]</span> SRS 就是讓 <span
        class="math inline">\(\mathbf{Z}\)</span> 在 <span
        class="math inline">\(\mathcal{S}\)</span> 上有均勻分布。 而既然
        <span class="math inline">\(\mathbf{Q}_{\sigma}\)</span>
        是雙射函數， 那對於任意 <span class="math inline">\(A \in
        \mathcal{S}\)</span>， <span
        class="math inline">\(\mathbf{Q}_{\sigma}^{-1} A\)</span>
        集合的大小和 <span class="math inline">\(A\)</span> 一樣， 即
        <span class="math inline">\(|\mathbf{Q}_{\sigma}^{-1} A| =
        |A|\)</span>。 所以， <span class="math display">\[
        \begin{aligned}
        P(\mathbf{Q}_{\sigma} \mathbf{Z} \in A)
        = P(\mathbf{Z} \in \mathbf{Q}_{\sigma}^{-1} A)
        = \frac{|\mathbf{Q}_{\sigma}^{-1} A|}{|\mathcal{S}|}
        = \frac{|A|}{|\mathcal{S}|}
        = P(\mathbf{Z} \in A).
        \end{aligned}
        \]</span> 所以，<span class="math inline">\(\mathbf{Q}_{\sigma}
        \mathbf{Z}\)</span> 與 <span
        class="math inline">\(\mathbf{Z}\)</span> 有相同的分配。
        既然如此， <span class="math display">\[
        \operatorname{E}(\mathbf{Z})
        = \operatorname{E}(\mathbf{Q}_{\sigma} \mathbf{Z})
        = \mathbf{Q}_{\sigma} \operatorname{E}(\mathbf{Z}),
        \]</span> 而 <span class="math inline">\(\mathbb{R}^n\)</span>
        中不變於任意排列矩陣的向量就是 <span
        class="math inline">\(\mathbf{1}_n\)</span> 的倍數， 所以 <span
        class="math inline">\(\operatorname{E}(\mathbf{Z}) = c
        \mathbf{1}_n\)</span>。 而因為 <span
        class="math inline">\(\mathbf{1}_n^\intercal \mathbf{Z} =
        n_1\)</span>， 所以 <span
        class="math inline">\(\mathbf{1}_n^\intercal
        \operatorname{E}(\mathbf{Z}) = n_1\)</span>， 因此 <span
        class="math inline">\(c = n_1 / n\)</span>。</p>
        <p>同理， <span class="math display">\[
        \operatorname{Cov}(\mathbf{Z})
        = \operatorname{Cov}(\mathbf{Q}_{\sigma} \mathbf{Z})
        = \mathbf{Q}_{\sigma} \operatorname{Cov}(\mathbf{Z})
        \mathbf{Q}_{\sigma}^\intercal.
        \]</span> 那 <span class="math inline">\(\mathbb{R}^{n \times
        n}\)</span> 中不變於任意排列矩陣的矩陣長什麼樣呢？
        注意到重排可以讓 <span
        class="math inline">\(\operatorname{Cov}(\mathbf{Z})\)</span>
        的對角線元素互換位置， 所以對角線元素必須都一樣。
        另外，重排也可以讓 <span
        class="math inline">\(\operatorname{Cov}(\mathbf{Z})\)</span>
        的非對角線元素互換位置， 所以非對角線元素也必須都一樣。
        因此，<span
        class="math inline">\(\operatorname{Cov}(\mathbf{Z})\)</span>
        必須是形如 <span class="math display">\[
        \operatorname{Cov}(\mathbf{Z})
        = c_1 \mathbf{I}_n + c_2 \mathbf{1}_n \mathbf{1}_n^\intercal.
        \]</span> 而因為 <span
        class="math inline">\(\mathbf{1}_n^\intercal \mathbf{Z} =
        n_1\)</span>， 所以 <span class="math display">\[
        \operatorname{Cov}(\mathbf{Z}) \mathbf{1}_n = \mathbf{0}_n,
        \]</span> 因此 <span class="math display">\[
        (c_1 \mathbf{I}_n + c_2 \mathbf{1}_n \mathbf{1}_n^\intercal)
        \mathbf{1}_n
        = (c_1 + c_2 n) \mathbf{1}_n = \mathbf{0}_n,
        \]</span> 所以 <span class="math inline">\(c_2 = -c_1 /
        n\)</span>。 因此，<span
        class="math inline">\(\operatorname{Cov}(\mathbf{Z}) = c_1
        \mathbf{P}_n\)</span>。 最後的問題是，<span
        class="math inline">\(c_1\)</span> 是多少？ 注意到任何 <span
        class="math inline">\(\mathbf{Z}\)</span> 都恰有 <span
        class="math inline">\(n_1\)</span> 個 <span
        class="math inline">\(1\)</span> 與 <span
        class="math inline">\(n_0\)</span> 個 <span
        class="math inline">\(0\)</span>， 故 <span
        class="math inline">\(\mathbf{Z}\)</span> 距離中心點 <span
        class="math inline">\(\frac{n_1}{n} \mathbf{1}_n\)</span>
        的距離會是 <span class="math display">\[
        \left\| \mathbf{Z} - \frac{n_1}{n} \mathbf{1}_n \right\|^2
        = n_1 \left(1 - \frac{n_1}{n}\right)^2 + n_0 \left(0 -
        \frac{n_1}{n}\right)^2
        = \frac{n_1 n_0}{n},
        \]</span> 而利用 <span
        class="math inline">\(\operatorname{trace}(\cdot)\)</span> 與
        <span class="math inline">\(\operatorname{E}(\cdot)\)</span>
        的線性， <span class="math display">\[
        \operatorname{trace}(\operatorname{Cov}(\mathbf{Z}))
        = \operatorname{E}[\| \mathbf{Z} - \operatorname{E}(\mathbf{Z})
        \|^2]
        = \frac{n_1 n_0}{n}.
        \]</span> 又因為 <span
        class="math inline">\(\operatorname{trace}(\mathbf{P}_n) = n -
        1\)</span>， 所以 <span class="math display">\[
        \operatorname{trace}(\operatorname{Cov}(\mathbf{Z}))
        = c_1 \operatorname{trace}(\mathbf{P}_n) = c_1 (n - 1),
        \]</span> 因此我們終於得到 <span class="math display">\[
        c_1 = \frac{n_1 n_0}{n(n - 1)}.
        \]</span></p>
    </main>

    <footer>
        <p>© 2025 小學生筆記</p>
    </footer>
</body>
</html>
