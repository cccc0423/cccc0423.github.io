[
  {
    "objectID": "misc.html",
    "href": "misc.html",
    "title": "其他",
    "section": "",
    "text": "Instrumental Variables in a Nutshell: A brief introduction to the IV, 2SLS, and control function approaches."
  },
  {
    "objectID": "misc.html#econometrics",
    "href": "misc.html#econometrics",
    "title": "其他",
    "section": "",
    "text": "Instrumental Variables in a Nutshell: A brief introduction to the IV, 2SLS, and control function approaches."
  },
  {
    "objectID": "misc.html#gallery",
    "href": "misc.html#gallery",
    "title": "其他",
    "section": "Gallery",
    "text": "Gallery\n\n名牌產生器：一個簡單的 \\(\\rm \\LaTeX\\) 名牌產生器。"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "小學生筆記",
    "section": "",
    "text": "⇦ ⇨ ↻ ⓘ\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n   \n     \n     \n       Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\nDate\n\n\nTitle\n\n\nSubtitle\n\n\n\n\n\n\nApr 5, 2025\n\n\n週記（十一）\n\n\n天地玄黃，宇宙洪荒\n\n\n\n\nMar 29, 2025\n\n\n週記（十）\n\n\n渾渾噩噩的一週\n\n\n\n\nMar 22, 2025\n\n\n週記（九）\n\n\n騎 YouBike 騎到不見\n\n\n\n\nMar 15, 2025\n\n\n週記（八）\n\n\n疲憊的一週\n\n\n\n\nMar 8, 2025\n\n\n週記（七）\n\n\n超沒效率的另一週\n\n\n\n\nMar 1, 2025\n\n\n週記（六）\n\n\n超沒效率的一週\n\n\n\n\nFeb 22, 2025\n\n\n週記（五）\n\n\n開學第一週\n\n\n\n\nFeb 15, 2025\n\n\n週記（四）\n\n\n開學前一週\n\n\n\n\nFeb 8, 2025\n\n\n週記（三）\n\n\n要趕緊決定碩論題目才行\n\n\n\n\nFeb 1, 2025\n\n\n週記（二）\n\n\n農曆新年\n\n\n\n\nJan 25, 2025\n\n\n週記（一）\n\n\n農曆年前的最後一週\n\n\n\n\nMar 4, 2023\n\n\nMilton Friedman 的恆溫器\n\n\n一個寓言故事\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/20250315-weekly-writing.html",
    "href": "posts/20250315-weekly-writing.html",
    "title": "週記（八）",
    "section": "",
    "text": "這週的疲憊主要是因為家教。家教學生（本系的專班學生）想要在四月底以前提出論文口試的申請，這意味我們這個月就要把大部分的工作搞定。我覺得他有點太樂觀了。原先資料分析的結果其實沒有預期的那麽好，還有很多東西需要調整。比如說我們跑了一些迴歸模型，發現 clustered standard errors 超級小，他的老師和他都覺得很棒、很有說服力，但我仔細想想才發現其中有詐。\n在當時的分析中，橫斷面的樣本只有 \\(2\\) 個，而我們計算 clustered standard errors 時容許同一個樣本在不同時點的觀測值之間有任意的自相關。我們的迴歸模型的係數至少有 \\(4\\) 個。這樣做會有很嚴重的問題。通常 clustered standard errors 的估計式形如 \\[\n\\widehat{\\operatorname{Var}}(\\hat{\\beta})\n\\propto \\left(\\mathbf{X}^\\intercal \\mathbf{X}\\right)^{-1} \\left(\\sum_g \\mathbf{X}_g^\\intercal \\hat{\\mathbf{e}}_g \\hat{\\mathbf{e}}_g^\\intercal \\mathbf{X}_g\\right) \\left(\\mathbf{X}^\\intercal \\mathbf{X}\\right)^{-1},\n\\] 其中 \\(\\mathbf{X}_g\\) 是第 \\(g\\) 個 cluster 的資料矩陣， \\(\\hat{\\mathbf{e}}_g\\) 是第 \\(g\\) 個 cluster 的殘差。 給定任意 \\(g\\)，因為 \\(\\operatorname{rank}\\left(\\hat{\\mathbf{e}}_g \\hat{\\mathbf{e}}_g^\\intercal\\right) = 1\\)， 所以 \\(\\operatorname{rank}\\left(\\mathbf{X}_g^\\intercal \\hat{\\mathbf{e}}_g \\hat{\\mathbf{e}}_g^\\intercal \\mathbf{X}_g\\right) = 1\\)， 而當 cluster 的數量 \\(G = 2\\) 時， \\[\n\\operatorname{rank} \\left(\\sum_g \\mathbf{X}_g^\\intercal \\hat{\\mathbf{e}}_g \\hat{\\mathbf{e}}_g^\\intercal \\mathbf{X}_g\\right) \\leq 2.\n\\] 因此 \\(\\widehat{\\operatorname{Var}}(\\hat{\\beta})\\) 的 rank 也不會超過 \\(2\\)。但這裡最少有 \\(4\\) 個參數要估計，所以 \\(\\widehat{\\operatorname{Var}}(\\hat{\\beta})\\) 的 rank 必須得是 \\(4\\)。事實上在現有的資料中，\\(\\sum_g \\mathbf{X}_g^\\intercal \\hat{\\mathbf{e}}_g \\hat{\\mathbf{e}}_g^\\intercal \\mathbf{X}_g\\) 甚至不是正定矩陣。 如此，統計軟體在計算 \\(\\widehat{\\operatorname{Var}}(\\hat{\\beta})\\) 時容易給出非常極端的數值。因此在此資料不適合這樣使用 clustered standard errors。解決辦法是至少讓 cluster 數量 \\(G\\) 大於參數數量。不過這樣的話，現有的資料就不夠了，又要再清理一些資料。做這些 data work 還不是最煩的，我更討厭使用 MS Word 把家教課和他說過的東西整理成一份文件。使用 Word 排版讓人身心很不舒適。總而言之，真是惡夢一場。"
  },
  {
    "objectID": "posts/20250315-weekly-writing.html#家教",
    "href": "posts/20250315-weekly-writing.html#家教",
    "title": "週記（八）",
    "section": "",
    "text": "這週的疲憊主要是因為家教。家教學生（本系的專班學生）想要在四月底以前提出論文口試的申請，這意味我們這個月就要把大部分的工作搞定。我覺得他有點太樂觀了。原先資料分析的結果其實沒有預期的那麽好，還有很多東西需要調整。比如說我們跑了一些迴歸模型，發現 clustered standard errors 超級小，他的老師和他都覺得很棒、很有說服力，但我仔細想想才發現其中有詐。\n在當時的分析中，橫斷面的樣本只有 \\(2\\) 個，而我們計算 clustered standard errors 時容許同一個樣本在不同時點的觀測值之間有任意的自相關。我們的迴歸模型的係數至少有 \\(4\\) 個。這樣做會有很嚴重的問題。通常 clustered standard errors 的估計式形如 \\[\n\\widehat{\\operatorname{Var}}(\\hat{\\beta})\n\\propto \\left(\\mathbf{X}^\\intercal \\mathbf{X}\\right)^{-1} \\left(\\sum_g \\mathbf{X}_g^\\intercal \\hat{\\mathbf{e}}_g \\hat{\\mathbf{e}}_g^\\intercal \\mathbf{X}_g\\right) \\left(\\mathbf{X}^\\intercal \\mathbf{X}\\right)^{-1},\n\\] 其中 \\(\\mathbf{X}_g\\) 是第 \\(g\\) 個 cluster 的資料矩陣， \\(\\hat{\\mathbf{e}}_g\\) 是第 \\(g\\) 個 cluster 的殘差。 給定任意 \\(g\\)，因為 \\(\\operatorname{rank}\\left(\\hat{\\mathbf{e}}_g \\hat{\\mathbf{e}}_g^\\intercal\\right) = 1\\)， 所以 \\(\\operatorname{rank}\\left(\\mathbf{X}_g^\\intercal \\hat{\\mathbf{e}}_g \\hat{\\mathbf{e}}_g^\\intercal \\mathbf{X}_g\\right) = 1\\)， 而當 cluster 的數量 \\(G = 2\\) 時， \\[\n\\operatorname{rank} \\left(\\sum_g \\mathbf{X}_g^\\intercal \\hat{\\mathbf{e}}_g \\hat{\\mathbf{e}}_g^\\intercal \\mathbf{X}_g\\right) \\leq 2.\n\\] 因此 \\(\\widehat{\\operatorname{Var}}(\\hat{\\beta})\\) 的 rank 也不會超過 \\(2\\)。但這裡最少有 \\(4\\) 個參數要估計，所以 \\(\\widehat{\\operatorname{Var}}(\\hat{\\beta})\\) 的 rank 必須得是 \\(4\\)。事實上在現有的資料中，\\(\\sum_g \\mathbf{X}_g^\\intercal \\hat{\\mathbf{e}}_g \\hat{\\mathbf{e}}_g^\\intercal \\mathbf{X}_g\\) 甚至不是正定矩陣。 如此，統計軟體在計算 \\(\\widehat{\\operatorname{Var}}(\\hat{\\beta})\\) 時容易給出非常極端的數值。因此在此資料不適合這樣使用 clustered standard errors。解決辦法是至少讓 cluster 數量 \\(G\\) 大於參數數量。不過這樣的話，現有的資料就不夠了，又要再清理一些資料。做這些 data work 還不是最煩的，我更討厭使用 MS Word 把家教課和他說過的東西整理成一份文件。使用 Word 排版讓人身心很不舒適。總而言之，真是惡夢一場。"
  },
  {
    "objectID": "posts/20250315-weekly-writing.html#修課",
    "href": "posts/20250315-weekly-writing.html#修課",
    "title": "週記（八）",
    "section": "修課",
    "text": "修課\n這週書法課練習了一些其他的筆畫。除了點挑、撇、橫畫以外，還練習了捺、豎勾、橫折、折彎鉤等等。智永的豎勾常常寫得像「蟹爪鈎」，這是王羲之的筆法，在後世的書法家中就比較少見了。這門課的老師非常強調調鋒，即運筆的過程中要不斷調整筆鋒使得可以中鋒用筆。舉例來說，寫豎勾的時候，筆畫下來以後要稍微繞一圈調整筆鋒，然後才出鋒。我能理解這種作法，因為調整筆鋒以後，什麼勾都寫得出來。而且如果一定要寫蟹爪鈎的話，這種來自於隸書的筆法，很難避免不先在豎畫的尾端調整筆鋒，否則勾的下方會有點破損。不過倒也不是什麼書體都得這麼麻煩，我學歐陽詢時的老師，就認為歐體的豎勾可以豎畫下來就直接出鋒。這樣比較自然，而且也挺合理的，畢竟歐體的豎勾是比較方正的。另外，還學習了一點點篆書的筆法，我感覺自己開始掌握到藏鋒的手感。其實這些練習終究都只是為了讓我們熟悉如何控制筆毛，以及如何調整筆鋒。基本功打好以後，寫什麼字帖都能夠自如。\n這週的統計學習課把 smoothing splines 教完，並介紹如何選擇 smoothing parameter，還教了 nonparametric logistic regression 與 reproducing kernel Hilbert spaces (RKHS)。說實話我覺得 RKHS 的部分是個大坑，因為我的數學基礎不夠（對泛函分析一無所知），所以很難理解，而仔細學習的效益又不高，只希望不要出相關的作業。"
  },
  {
    "objectID": "posts/20250315-weekly-writing.html#研究與閱讀",
    "href": "posts/20250315-weekly-writing.html#研究與閱讀",
    "title": "週記（八）",
    "section": "研究與閱讀",
    "text": "研究與閱讀\n週四早上跟 YC 聊聊。結論是，他覺得畢竟我要唸 PhD，可以先嘗試自己找找看研究題目。一個方法是多看 applied 的文章然後挑毛病。他說他自己也常這樣找題目。他說我可以每週看個 5 篇然後和他分享一下有什麼心得。這真是一則以喜，一則以憂。值得高興的是他願意花時間（真感謝😔），不過這樣我又更忙了，5 篇文章真的好多，要好好規劃時間才行。"
  },
  {
    "objectID": "posts/20250315-weekly-writing.html#其他",
    "href": "posts/20250315-weekly-writing.html#其他",
    "title": "週記（八）",
    "section": "其他",
    "text": "其他\n週四下午離開衛福部以後，因為晚上需要家教，就先去市政府站附近晃晃。我拿了之前送修的雨傘。本來想去時代百貨二樓的星巴克坐坐，但人好多😅。附近去過的兩家咖啡廳，一家今天被包場了，一家沒開。於是我第一次去了客美多。感覺普普通通，不過有插頭很方便。"
  },
  {
    "objectID": "posts/20250215-weekly-writing.html",
    "href": "posts/20250215-weekly-writing.html",
    "title": "週記（四）",
    "section": "",
    "text": "這週暈頭轉向，不知道自己在做什麼。每天都睡不好，早上起床時總是覺得沒有休息足夠。根據 Apple Watch 顯示，一晚可以醒來十多次。又或者，我會做一些很複雜的夢。週二晚上至週三的夢境有被我簡單記錄下來。\n我在夢裡也在做夢。夢中的夢經過各地——那些在我潛意識中重要的地方——旅行。最後在一家餐廳用餐。一個以前的學長與他的家人也在那裡。奇怪的是他裸著上身用餐。我在夢裡看到這個人，不禁感懷與這個人相處的過程，想到大概很久以後才會再見了，當下還百感交集碩二上正式結束了。\n然後我從夢中夢醒來。到了白天，不知為何我開始練習滑板，然後我和另一位高中同學交談。或許這也是我比較懷念的人。我們交談直到我意識到我在做夢。\n最近幾週心情都莫名其妙地悲痛，也常常想起一些難以理解的回憶。\n我想到一個以前認識的人。快兩年前，他斷崖式地消失了，還封鎖我的 Instagram 和 Twitter，刪除了我的臉書。1 不知道對方如何看待我。不過直到現在我還是認為對方有很多優點。難以理解他為何這樣對待我——儘管我也知道我有很多缺點，但也不至於此吧！我感覺這件事情帶給我不小的創傷。而我因此情緒低落好久。\n直到現在，有些人際互動中的小小片段還是讓我想起這份難堪的回憶。我只能慶幸自己還能覺得受傷，而不至於麻木不仁，因為這是我曾經真誠付出感情的證明。\n但是，要怎麼超越這份悲痛？不知道，希望我還能成長，變成更好的人。\n我報名了今年 5 月的 GRE 考試。這意味著應該要好好開始準備了。先從背 Magoosh 的單字開始吧。\n週四下雨。我想測試看看怎麼去衛福部比較快，於是我計劃從住處騎腳踏車到忠孝敦化，然後再搭捷運到昆陽。當天下雨，結果我在仁愛圓環摔倒。路人紛紛轉頭看我。有點糗，不過我快速地起身，確認只有一點小挫傷後，趕緊騎腳踏車離開。但好像有點頭暈了，竟然在仁愛路上迷路，繞了一下才確定方向。\n從衛福部離開以後，我搭捷運到市府轉運站的傘店送修早上因為摔倒而弄壞的雨傘。送修要等一個月，所以我想著再買一把傘備用。店裡阿姨一直推薦我買一把很樸實機能性很好的傘，但我一直覺得外觀不太好看。最後我買了一把有趣的花花雨傘。晚上晾衣服，看到去日本旅遊買的 Snoopy 帽 T，覺得應該多買一點有趣的衣服才對。這時我突然想通為什麼自己想買有趣的傘：因為我本人太無聊了，應該要多買一些有趣的東西😔。\n晚餐在時代百貨裡吃大戶屋。鄰座是一對母子。男生感覺年紀比我大一兩歲，他和他的媽媽邊吃飯邊聊天。我很羨慕他和他媽媽的互動。他媽媽和他說最近自己去了昆明旅遊，還和他抱怨最近公司人事調度。只聽聲音可能還會以為是朋友間的談話。\n我從小就沒怎麼經歷社會化。我爸媽很少出門，也很少帶我出門、讓我出門。所以我大部分的人際關係都很扁平。也因此我相對於別人一直都不那麼理解社會規範。這有好有壞，畢竟所謂社會規範同樣是有好有壞。\n以戀愛關係而言，因為小時候幾乎沒有看過影劇漫畫，我爸媽也不太展現那些典型的互動模式（雖然我爸媽並不是很好的範本）。不過在我心中，一切就是很樸素的兩個人喜歡彼此、對彼此好。我真的很晚才學習到那套主流的異性戀的戀愛腳本（比如男生要怎麼寵女生，女生要如何暗示男生等等）。隨著年紀越來越大越討厭這套腳本。可惜我讀的書不夠多，有口難言，很難說清楚為何我不喜歡這套腳本。一開始可能是因為覺得俗氣，後來慢慢覺得背後有更多問題。在此從略。不過我就是不明白，為什麽不能只是因為感受到對方的心意而開心？\n不太理解社會規範這件事還可以應用到很多其他場合。似乎我就是非常我行我素，只要我覺得是對的，重要的事情，就不想退讓。改天想到再寫。\n週五下午又參加 EMI TA 培訓。\n因為擔心另外兩位計量導的 TA 都沒有參與 EMI TA 培訓，到時候報帳或 TA 資格會比較麻煩，因此我去年就參加過一次 EMI TA 培訓。但後來顯然是多慮了，KM 其實沒有成功申請到 EMI 的補助，所以我雖然全程參加，但最後想著「我以後應該不會需要擔任 EMI TA 吧」，就沒有繳交某些文件。\n結果今年換我要當計量導的 EMI TA。週五下午又花了兩個小時參加培訓，幾乎所有環節都與去年一樣。這種場合真的是什麼人都有。第一小時，與我同桌的一個男生（亞洲人，但英語口音並不是中文或者常見的英語系國家口音）一直吃東西，徒手抓著麵包，手指沾了奶油。他比手畫腳之間，還把麵包屑撥到他旁邊男生身上。第二小時，我參與設計活動的場次。我們要設計一個課堂活動，讓學生預習或複習全球暖化的知識。同組有個讀醫學工程的女生，英文講得很好，口音也很標準美式，但感覺大家都聽不太懂他在說什麼。就這樣度過了兩個小時。"
  },
  {
    "objectID": "posts/20250215-weekly-writing.html#footnotes",
    "href": "posts/20250215-weekly-writing.html#footnotes",
    "title": "週記（四）",
    "section": "Footnotes",
    "text": "Footnotes\n\n\n直到最近幾個月，他又解封了我的 Twitter 然後重新追蹤我，但我們沒有任何互動。↩︎"
  },
  {
    "objectID": "posts/20230304-friedman-thermostat.html",
    "href": "posts/20230304-friedman-thermostat.html",
    "title": "Milton Friedman 的恆溫器",
    "section": "",
    "text": "Milton Friedman，諾貝爾經濟學獎得主，說過以下的一個寓言故事。\n想像有一棟屋子，裡面有一臺很棒的恆溫器。恆溫器吃油，添油進去、燒更多的油，屋子裡就會變得溫暖。\n這時候我們當然好奇，恆溫器吃了多少的油、屋內的溫度與屋外的溫度之間的關係。我們可能會把這些資料紀錄下來——在不同的時點，紀錄當下的油耗，以及屋內外的溫度。\n觀察這些資料，我們可能會發現兩件驚人的事：其一，恆溫器的油耗與屋外的溫度呈現高度的負相關。這意味著，燒越多油，屋外的溫度越低嗎？而且，我們還發現恆溫器的油耗與屋內的溫度並沒有關聯，這意味著，即便燒再多的油，屋內的溫度都不受其影響嗎？\n當然不會是這樣。這是因為屋內的溫度同時由恆溫器的油耗量與屋外的溫度所決定；換言之，恆溫器的油耗與屋外的溫度，都是屋內的溫度的「原因」。如果添越多油給屋內加熱，屋內的溫度當然會越高；如果屋外的溫度越低，屋內的溫度也將越低。\n但是，另一方面，恆溫器有固定屋內溫度的效果，因此我們只觀察到同一屋內溫度的資料。當我們只觀察同樣的屋內溫度，屋外的溫度越低，恆溫器就得要更努力吃油以維持屋內的溫度。故我們會發現恆溫器油耗與屋外溫度的負向關聯；也因為恆溫器固定了屋內溫度，所以觀察到恆溫器油耗竟然與屋內溫度無關。"
  },
  {
    "objectID": "posts/20250125-weekly-writing.html",
    "href": "posts/20250125-weekly-writing.html",
    "title": "週記（一）",
    "section": "",
    "text": "第一篇週記。這篇週記的主題是搬家、科學哲學與同學會。希望以後能養成每週寫一篇週記的習慣。閱讀的部分有點寫太多了，這並不是壞事，但以後應該會減少一點。"
  },
  {
    "objectID": "posts/20250125-weekly-writing.html#搬家",
    "href": "posts/20250125-weekly-writing.html#搬家",
    "title": "週記（一）",
    "section": "搬家",
    "text": "搬家\n這週最重要的事情莫過於搬家。\n我在公館的租屋處如高嘉瑜的房間一般雜亂。上週五被室友兼房東催促收拾。這件事確實是我應該做的，但是我卻一直拖延。他說要是不整理乾淨，租約到 3 月底就不再續約。我回覆他我會盡快整理。我一方面覺得羞恥，一方面覺得罪惡，但是又覺得他態度太差。不知道是不是我的誤會，我常常覺得因為我與他沒有私交，要是房子出現什麼他不滿意的地方，他通常會認為是我造成的，而不是另一個室友造成的（但是經常是另一個室友造成的，例如衣服沒收什麼的）。這件事情像是導火線。因為這個地點和這個房間都太不宜居，我一直覺得我應該要搬家，但是又覺得搬家很麻煩，而且我也不知道要搬到哪裡。這次終於下定決心要辦家。\n按捺不住各種負面情緒，當晚很難入睡，一直忍不住滑手機，瀏覽各個臉書社團與 591 平臺上的招租。當下記了一些，私訊了其中一個房東。隔天早上起來看到房東回覆，要我打電話給他。我打了，約了時間，下午去看房。房東一開始接到電話好像還以為我是女生。他說他們的房子是限男，我還跟他說我是男生（可能因為我當下聲調比較高）。房東年紀 70 歲，話蠻多的，蠻主動跟我介紹一些有的沒的；穿著屬於得體老人，他的羽絨外套、長褲和皮鞋都感覺做工不錯。他說前房客是機械系的學生，從大學到碩班和他租了很多年，但要去工作了。我跟他說我大概就租一年，他問我怎麼不讀博班，我說可以的話想出國讀，可能去美國。他說他弟弟也在華盛頓特區讀過法律，以前是政府的公務員，後來也在大學教課（上網查一下發現他弟弟感覺蠻有名的😓）。總之，新住處的事情很快就搞定了，之後會住在科技大樓附近。\n在新住處的事情搞定後，接下來我努力把舊住處搬空並清理乾淨。扛著大包小包的垃圾與回收物，步行反覆來回於舊住處與清潔隊之間（大約 1 公里）真的很累。除了一些真的毫無利用價值的垃圾，我也丟掉很多還算能用的東西。。並且，我也一邊把東西搬到新住處。\n最棘手的問題是怎麼處理舊住處的租約。週二晚上我和他說我已經搬空並清潔完畢，如果可以的話我就歸還鑰匙。因為算是我想要提早解約，所以押金我就不取回了。他已讀。我週四早上忍不住和他說，如果沒問題的話，我隔天會去歸還鑰匙。他回他不在臺北。於是這件事大概要再拖延到二月。\n我從 2022 年 4 月正式搬入舊住處。原先住在 BOT 宿舍的雙人房，因為很受不了室友的生活習慣，決定要搬到外面。當時犯的最大錯誤就是租在舊住處。租給我的對象是舊住處的其中一個室友，也就是前文所稱的「室友兼房東」，他似乎是臺科大的畢業生，據聞他已經租在這裡 12 年了。真正的房東把整層公寓租給他，然後他將多餘的房間出租給其他人。他並不是職業房東，當時的我也沒什麼社會經驗😓，所以我們當時沒有簽下白紙黑字的合約。現在我要搬走，我蠻擔心自己的權益會受損。\n\n\n\n\n\n\n2025/1/31 更新\n\n\n\n房東讓我把鑰匙歸還了。這件事情算是告一段落了。"
  },
  {
    "objectID": "posts/20250125-weekly-writing.html#閱讀",
    "href": "posts/20250125-weekly-writing.html#閱讀",
    "title": "週記（一）",
    "section": "閱讀1",
    "text": "閱讀1\n這週讀了 Philosophy of Science: A Very Short Introduction。我第一次讀這系列（A Very Short Introduction, VSI）的書，它們由牛津大學出版社出版，每一本書都簡潔地介紹一個主題，是很棒的通識讀本。這本書的內容包括科學的定義、科學推論、科學解釋、科學革命、實在論與反實在論與對科學的批評等等。雖然大部分都是我已經知道的知識，但是作者用簡短的文字將這些知識點串連起來，還是讓我更清楚地認識科學哲學的基本概念。以下摘要與評論其中一些我覺得比較有趣的主題：什麼是科學？什麼是科學推論？什麼是科學解釋？\n\n什麼是科學？\n什麼是科學？二十世紀赫赫有名的科學哲學家 Karl Popper 認為科學最重要的特徵就是科學理論得要是可以被否證的（falsifiable）。所謂「可否證的」，即是指科學理論必須要有可能被實驗或觀察所推翻的預測。Popper 認為不可否證的理論不配被稱作科學，僅僅只是偽科學。\nPopper 以佛洛依德的心理學和馬克思的歷史唯物主義為例，主張這兩者都是不可否證的理論，因此不是科學；無論病人出現怎樣的行為，信奉佛洛伊德的精神分析學家總是可以找到一種佛洛依德式的解釋，相似地，就算工業社會沒有從資本主義過渡到社會主義，馬克思主義者也總是可以找到一種符合馬克思理論的解釋。\nPopper 認為愛因斯坦的廣義相對論即是一個鮮明的對照，其預測光線會受到太陽的重力場影響而彎曲，滿足可否證性的標準。而這個預測也在 1919 年的日食實驗中被證實。因此，愛因斯坦的理論是科學，而佛洛伊德和馬克思的理論則不是。\n但是許多科學哲學家認為 Popper 的可否證性標準有點過於簡單了。Popper 指控精神分析學家和馬克思主義者在遇到與他們的理論相牴觸的證據時，他們會想辦法去找一個解釋，而不是放棄他們的理論。但是，這種行為在科學界也是普遍存在的。以牛頓的重力理論為例，它成功地預測了許多行星運動的軌跡，但是天王星的運動卻與牛頓的理論預測不符。John Adams 與 Urbain Leverrier 並沒有放棄牛頓的理論，而是提出了一個假設，即天王星的運動是由於另一顆還未被觀測到的行星的重力影響。他們並根據牛頓的理論預測了那顆尚未被發現的行星的質量與位置。他們的預測幾乎與後來發現的海王星吻合。大家通常不會說 Adams 與 Leverrier 的行為是不科學的，但是他們做的事情就像是 Popper 對於精神分析學家與馬克思主義者的批評一樣——他們在遇到證據與他們的理論相牴觸時，他們並沒有放棄他們的理論，而是想辦法去找一個解釋。此外，水星在近日點的運動也與牛頓的理論預測不符，但是科學家並沒有放棄牛頓的理論，他們起初想要如法炮製天王星的成功案例，提出了一個假設，即水星的運動是由於另一顆還未被觀測到的行星的重力影響。但是他們並沒有找到這顆行星，而是等到愛因斯坦提出廣義相對論，其預測的數值完全符合觀測結果。綜合這些例子，我們可以看到科學家在遇到證據與他們的理論相牴觸時，他們並不會立刻放棄他們的理論，這種行為在科學界是普遍存在的，因此 Popper 的可否證性標準可能不是一個很好的科學標準。\n所以我們真的有辦法找到科學的一些共通的特徵嗎？就像維根斯坦的家族相似性那樣，許多東西被稱為遊戲，它們具備某些相似的特徵，但我們無法找到定義特徵來界定遊戲。科學也許就是這樣。\n\n\n科學推論\n科學家透過科學推論得出結論？但什麼是科學推論？\n邏輯學家區分出兩種推論：演繹（deductive）推論與歸納（inductive）推論。演繹推論是從一些前提（premises）推出一個結論（conclusion），而當前提是真的時，結論也必定是真的。以著名的例子來說：\n\n所有人都會死。\n蘇格拉底是人。\n所以，蘇格拉底會死。\n\n前提 1 與 2 是真的，所以結論 3 也必定是真的。這樣的推論即是演繹推論。但是並非所有推論都是演繹的。例如：\n\n前 5 個雞蛋都是好的。\n整盒雞蛋的有效日期都是一樣的。\n所以，第 6 個雞蛋也是好的。\n\n這樣的推論並非演繹的，因為前提 1 與 2 都成立，邏輯上也並不隱含結論 3。這樣的推論即是歸納推論。在歸納推論中，我們通常從一些我們已經見過的事實推斷出一個我們還沒有見過的事實。\n雖然演繹推論比起歸納推論更安全，但科學家也經常使用歸納推論。舉例來說，遺傳學家告訴我們唐氏症患者的第 21 對染色體有三條，而正常人只有兩條。但是這並不是因為遺傳學家看過所有的唐氏症患者的染色體，而得出這個結論的。他們只是看過一些唐氏症患者的染色體，然後推斷出所有唐氏症患者的染色體都是這樣的。這就是一個歸納推論。\n雖然歸納推論在科學裡很常見，但 Karl Popper 卻認為科學家不應該使用歸納推論，而只使用演繹推論。他的論點如下，雖然科學理論或假說不可能被有限的資料所證明（proved），但是卻可以被否證或推翻。例如，我們可以通過觀察一個黑天鵝來推翻「所有天鵝都是白色」這個假說。但是，我們無法通過觀察一個白天鵝來證明這個假說。但問題是，科學家的目標並不只是想要推翻理論，還想要確定哪些理論是正確的。為了達到這個目標，科學家必須使用歸納推論。\n但是，休謨稱使用歸納推論無法被合理的證成。注意到我們使用歸納推論時，我們似乎假定了自然的一致性（uniformity of nature）。例如，我們看到太陽每天都從東方升起，我們就假定明天太陽也會從東方升起。但是，我們無法證明自然的一致性。我們可以很輕易地想像一個自然不一致的世界。那麼，自然的一致性可以用經驗推論出來嗎？答案是否定的，因為這陷入了循環論證；我們不能因為自然經常是一致的，就認為自然總是一致的。因此，休謨認為，人相信歸納法並非因為它是合理的，而是因為動物本能使然。\n此外還有一種推論，如以下作者舉出的範例：\n\n儲藏室裡頭的起司不見了，留下一點碎屑。\n昨晚儲藏室裡似乎傳出了抓取東西的聲音。\n所以，起司被老鼠吃掉了。\n\n顯然這不是演繹推論。它稱為推論到最佳解釋（inference to the best explanation），也有人稱之為溯因推理。這種推論的基本思想是，我們應該選擇那個能夠最好解釋我們觀察到的現象的解釋。問題在於，哪些假說是最好的解釋？常見的標準是，一個好的解釋應該是簡單的。考慮以上的例子。我們可以考慮一個對立的假說，即起司是被女傭吃掉的，而他留下一些碎屑讓它看起來像是老鼠的傑作，而昨晚儲藏室的聲音其實是來自燒開水時水壺過熱發出的聲音。但是，我們通常會選擇老鼠這個解釋，因為女傭假說需要更多的假設而更複雜。不過，下一個問題是，為什麼我們會認為簡單的解釋是好的解釋？這個問題並沒有一個很好的答案。\n作者最後談到因果推論與機率。以後應該會有很多機會寫到，暫且不提。\n\n\n科學解釋\n科學家嘗試解釋世界。但是什麼是科學解釋？當代的討論主要從 Carl Hempel 的覆蓋律模型（covering law model）或稱為演繹—律則模型（deductive-nomological model）開始。Hempel 作為一個邏輯實證主義者，他試圖從形式的角度刻劃科學解釋的結構。這個模型的基本思想是，科學解釋由兩部分組成：一是解釋項（explanans），即解釋的前提；二是被解釋項（explanandum），即解釋的現象。解釋項由普遍的律則（general law）與具體的事實或初始條件（initial conditions）組成，而解釋項必須在邏輯上推出被解釋項。\n但是覆蓋律模型有一些著名的問題。2 首先是對稱性的問題。假設我們想要解釋為何旗杆的影子長度是 \\(20\\) 公尺。一個可能的解釋是，\n\n因為旗杆的高度是 \\(15\\) 公尺，而太陽的仰角是 \\(37^\\circ\\)，所以，根據三角函數，影子的長度應該是 \\(20\\) 公尺。\n\n這個解釋是合理的，也符合覆蓋律模型。但是，如果我們想要解釋為何旗杆的高度是 \\(15\\) 公尺，我們也可以說，\n\n因為旗杆的影子長度是 \\(20\\) 公尺，而太陽的仰角是 \\(37^\\circ\\)，所以，根據三角函數，旗杆的高度應該是 \\(15\\) 公尺。\n\n這個解釋也是合理的，也符合覆蓋律模型。但是我們通常認為前者是一個好的解釋，而後者不是。關鍵在於我們經常期望解釋項與被解釋項的關係是不對稱的。覆蓋律模型無法捕捉這種不對稱性。另一個問題來自於無關緊要的解釋項。比如說，如果我們問醫生，「為什麼那個男人沒有懷孕？」而醫生回答說，\n\n因為他定期服用避孕藥數年，而定期服用避孕藥的人不會懷孕，因此那個男人不會成爲孕婦。\n\n就算醫生說的是真的，那個男人真的定期服用避孕藥，但我們不會認為這是一個好的解釋。正確的解釋應該是，「因為他是男人。」重點在於，好的解釋應該包含對於被解釋項的發生的關鍵因素。覆蓋律模型無法捕捉這種關鍵性。\n既然覆蓋律模型有這些問題，哲學家當然試圖提出其他理解科學解釋的方式。其中一支文獻涉及因果性。同樣地，因為應該還有很多機會寫到這個主題，暫且不深入討論。不過，以上述兩個例子而言，訴諸因果性的方案確實避免了覆蓋律模型的問題。考慮旗杆問題。為什麼我們的直覺告訴我們給定普遍的律則，旗杆的高度解釋了影子的長度，而反之不然。這是因為旗杆的高度是影子長度為 \\(20\\) 公尺的原因，而反之不然。通常我們認為因果性是不對稱的關係，因此它避免了覆蓋律模型的對稱性問題。同樣地，因果性也避免了無關緊要的解釋項問題。如果我們問醫生為什麼那個男人沒有懷孕，而醫生回答說，「因為他是男人。」這個解釋是好的，因為男人不會懷孕是因為他是男人。這個解釋包含了對於被解釋項的發生的關鍵因素。"
  },
  {
    "objectID": "posts/20250125-weekly-writing.html#同學會",
    "href": "posts/20250125-weekly-writing.html#同學會",
    "title": "週記（一）",
    "section": "同學會",
    "text": "同學會\n說是同學會，只找了 10 個人，但說不是同學會，我們也見到高中班導了。\n最近幾天一些以前的高中同學揪了一團週末在臺中聚聚。於是我週六早上八點半從臺北搭高鐵自由座到新烏日，然後搭火車到臺中車站。\n早上聽了一會同學預約的旅客服務中心提供的車站附近的導覽，然後溜去吃宮原眼科，這是我第一次吃。搭計程車到豐樂公園。車上播放民視新聞，有個同學提及另一個同學並不相信柯文哲有貪污，很難跟他辯論。3 司機（疑似深綠）就繃不住了。4午餐在豐樂公園附近吃了義大利麵，附近的迪卡儂晃晃，然後玩了鐳射🔫。\n晚餐時間進到文心秀泰裡閒晃，竟然遇到高中班導。我高中畢業以後就沒看過他，至今五年多，他感覺沒什麼變老，而且好像還稍微變瘦了。他跟他的太太和三個孩子剛吃完飯，準備離開。他也覺得很驚訝。我們一行人，他唸了其中三個人的名字，但他搭著我的肩說「啊想不起來你的名字了，你是那個轉班的。」5 然後大家合影留念。最後在公園玩了一會在迪卡儂買的海綿球，就像高中時代一樣，然後回家。"
  },
  {
    "objectID": "posts/20250125-weekly-writing.html#footnotes",
    "href": "posts/20250125-weekly-writing.html#footnotes",
    "title": "週記（一）",
    "section": "Footnotes",
    "text": "Footnotes\n\n\n值得一寫但不值得單獨一篇的內容。↩︎\n這裡僅僅只是列出書上所提及的問題。事實上，此模型的問題還有更多。比如說，如果有人認同經濟學是一門科學（先不論他為何會如此覺得），那他應該也很難認同覆蓋律模型成功描繪了所有科學解釋的樣貌——絕大多數經濟解釋無法適配這樣的結構。↩︎\n我不曉得他到底有沒有貪污。↩︎\n接下來的行程全部都在發表政治意見😅是蠻有趣的啦，但也很沒營養。例如他為了論證自己沒有政黨傾向，說自己最敬佩的三個政治人物都是國民黨籍，而且我們可能都不認識。我馬上就猜到是哪三個——答案是：蔣經國、孫運璿、李國鼎（請反白）。↩︎\n他是我高一、二的班導，我高三轉讀社會組。↩︎"
  },
  {
    "objectID": "posts/20250301-weekly-writing.html",
    "href": "posts/20250301-weekly-writing.html",
    "title": "週記（六）",
    "section": "",
    "text": "仍然零進度。如果要說有讀什麼書的話，大概就是讀 ESL。我覺得我的問題在於線性代數打從一開始就沒學好，而且都還給謝銘倫了。我覺得我沒有那種一眼看穿習題走向的能力，這顯示我沒有完全掌握課程內容。有點挫折。\n有空的話應該要好好複習一下線性代數。不過這件事應該得等我確定碩論題目以後再做。"
  },
  {
    "objectID": "posts/20250301-weekly-writing.html#研究與閱讀",
    "href": "posts/20250301-weekly-writing.html#研究與閱讀",
    "title": "週記（六）",
    "section": "",
    "text": "仍然零進度。如果要說有讀什麼書的話，大概就是讀 ESL。我覺得我的問題在於線性代數打從一開始就沒學好，而且都還給謝銘倫了。我覺得我沒有那種一眼看穿習題走向的能力，這顯示我沒有完全掌握課程內容。有點挫折。\n有空的話應該要好好複習一下線性代數。不過這件事應該得等我確定碩論題目以後再做。"
  },
  {
    "objectID": "posts/20250301-weekly-writing.html#其他",
    "href": "posts/20250301-weekly-writing.html#其他",
    "title": "週記（六）",
    "section": "其他",
    "text": "其他\n最近在住處附近探索好吃的餐廳。週日我去漢堡叔叔買晚餐。漢堡叔叔是和平東路上的一家漢堡店。點完餐以後在店內等餐時，聽到不遠處有一桌大學生在聊天。仔細聽對話內容，發現是經原課的學生，甚至，是 lab 的大學生。他們的話題交錯。像是他們也聊到 lab 的尾牙和前陣子的迎新抽獎。我一直希望我沒有被發現，因為我穿拖鞋，而且不是很想跟不熟的人說話。正當我低著頭滑手機，一邊祈禱他們不要注意到我時，突然發現一個好消息與一個壞消息。好消息是，他們好像沒有注意到我。壞消息是，其中一個人為了介紹各種職稱（如研究助理、教學助理等等）的工作內容，拿我當教學助理的例子，提到我的名字😅。\n週三的時候好像因為吃壞肚子（但其實我也沒吃什麼⋯⋯），身體不太舒服。週四睡一覺起來（翹掉週四早上本來要去的衛福部😅），原本以為應該有好轉一些，結果下午到晚上更是全身肌肉酸痛。我從週四傍晚睡到週五下午，起床後才覺得身體恢復正常。\n週五下午吃了營養師的光合廚房，一家在科技大樓捷運站附近的健康餐廳。點了酸菜梅花肉鍋。味道不差，不過我覺得價格有點小貴，因為火鍋似乎有太多競爭者，而火鍋要吃得健康其實不難，只要別點重口味的湯底就好，像我每次吃聚這種連鎖火鍋店也都點那種最便宜的昆布湯底，因為我真的喜歡清淡的味道。總之，如果下次還吃的話，應該點別的。\n週六下午見了一個來臺北玩的高中同學。有一陣子沒見了。隨意走到瑞安街某條小巷的咖啡廳坐著聊天，然後走來走去，又走到臺大，在後門附近逛了一下。"
  },
  {
    "objectID": "posts/20250329-weekly-writing.html",
    "href": "posts/20250329-weekly-writing.html",
    "title": "週記（十）",
    "section": "",
    "text": "這週書法課繼續寫字。寫字真的很能夠消磨時間。\n這週的統計學習課主要教 local polynomial regression。這部分感覺還算重要，有空應該好好研讀😔。下週教 model selection，我已經大致上看了除了 VC dimension 以外的內容了（雖然還沒仔細研讀），要不是在計量課學過一些些，還真的會完全沒有概念，被牽著鼻子走（開學以來大部分的主題對我來說都是陌生的，因此常發生這樣的事）。"
  },
  {
    "objectID": "posts/20250329-weekly-writing.html#修課",
    "href": "posts/20250329-weekly-writing.html#修課",
    "title": "週記（十）",
    "section": "",
    "text": "這週書法課繼續寫字。寫字真的很能夠消磨時間。\n這週的統計學習課主要教 local polynomial regression。這部分感覺還算重要，有空應該好好研讀😔。下週教 model selection，我已經大致上看了除了 VC dimension 以外的內容了（雖然還沒仔細研讀），要不是在計量課學過一些些，還真的會完全沒有概念，被牽著鼻子走（開學以來大部分的主題對我來說都是陌生的，因此常發生這樣的事）。"
  },
  {
    "objectID": "posts/20250329-weekly-writing.html#研究與閱讀",
    "href": "posts/20250329-weekly-writing.html#研究與閱讀",
    "title": "週記（十）",
    "section": "研究與閱讀",
    "text": "研究與閱讀\n這週同樣看了一些 reduced form 的文章。\n\nBraakmann, Chevalier and Wilson (2024)\n這篇文章發表在 AEJ: Applied，標題是 Expected Returns to Crime and Crime Location。作者研究犯罪的期望報酬對犯罪地點的影響。\nBecker (1968) 把犯罪視為一種經濟決策。如果犯罪的預期回報高於其成本，則人就會去犯罪。大部分的實證文獻都研究勞動市場的條件與逮捕或判刑機率對犯罪的影響，但很少有文獻研究犯罪的期望報酬本身對於犯罪的影響。本研究評估犯罪期望報酬的變化不僅改變了犯罪的性質，還改變了犯罪的地點。\n南亞裔家庭有儲存黃金、珠寶在家中的文化習俗。這樣的習俗也因為媒體報導，為英國大眾熟知。作者搜集了 2011 年至 2019 年英格蘭和威爾斯每月的鄰里層級的犯罪資料，並利用 2011 年人口普查資料，將南亞裔人口密度較高的鄰里劃分為實驗組。接著將這些資料與英國的每月黃金價格相結合，並估計以下模型： \\[\ny_{ict} = \\beta_0 + \\beta_1 \\mathit{SA}_{ic} + \\beta_2 \\mathit{GP}_t + \\tau \\big( \\mathit{SA}_{ic} \\times \\mathit{GP}_t \\big) + \\alpha_c + \\theta_t + \\gamma \\mathit{TREND}_{it} + \\varepsilon_{ict},\n\\] 其中 \\(y_{ict}\\) 是鄰里 \\(i\\) 在區域 \\(c\\) 時間 \\(t\\) 的犯罪率，\\(\\mathit{SA}_{ic}\\) 是鄰里 \\(i\\) 是否屬於南亞裔人口密度較高的區域，\\(\\mathit{GP}_t\\) 是時間 \\(t\\) 的黃金價格，\\(\\mathit{TREND}_{it}\\) 是鄰里的時間趨勢，\\(\\alpha_c\\) 是區域固定效果，\\(\\theta_t\\) 是月固定效果，\\(\\varepsilon_{ict}\\) 是誤差項。作者並把黃金價格與犯罪數都做了 inverse hyperbolic sine 轉換，以便詮釋成彈性。\n研究結果發現，南亞裔鄰里的竊盜犯罪對黃金價格變動的敏感度是其他同一區域鄰里的兩倍。黃金價格上漲使得南亞裔鄰里的竊盜犯罪相對於其他鄰里會顯著增加。\n大家都會說自己在做 DiD，不過他們做的事經常偏離經典的 DiD 設計。我的疑問包括：\n\n黃金的價格是連續變數。這時候的 fixed effects 迴歸真的能給出有因果詮釋的係數嗎？\n有 47% 的觀察值的竊盜案發生數是 0，因此作者用了 inverse hyperbolic sine 轉換。這樣的轉換是否合理？他引用了 Bellemare and Wichman (2019) 在 Oxford Bulletin of Economics and Statistics 的文章。另外，Chen and Roth (2023) 的 QJE 也討論這個問題。\n續 2，在穩健性檢驗中，作者也用絕對值的竊盜案發生數，並且改用 fixed effects Poisson regression。這樣的做法是否合理？我懷疑並不合理，原因有二。\n\n首先，Poisson regression 要求條件平均值等於條件變異數，但是大部分的觀察值都是 0，所以這個假設很可能不成立。\n其次，這其實有 zero-inflated 的問題，但是作者並沒有考慮到。在因果推論上，這邊比較深一點的問題大概跟 extensive margin 和 intensive margin 可以扯上關係，但我還想不太清楚。\n\n\n有空的話我應該去看看 Bellemare and Wichman (2019) 和 Chen and Roth (2023) 的文章。\n\n\nCunha (2014)\n因為跟 KM 的研究正需要看文獻有什麼發現，所以看了這篇文章。這篇文章發表在 AEJ: Applied，標題是 Testing Paternalism: Cash versus In-Kind Transfers。作者研究政府以實物（in-kind transfer）而非現金形式提供福利的合理性。\n家父長式的（paternalistic）政府會選擇以實物形式提供福利，因為他們認為這樣可以確保福利用於正確的地方。為什麼不發放等值的現金呢？一個家父長式的政府會認為，如果福利以現金形式發放，接受者可能會把這筆錢用在不當的地方。注意到如果政府提供的實物移轉的量少於接受者在沒有該移轉但擁有等值現金時會消費的量時，接受者即使收到等值的現金，也會至少消費這麼多的該項物品。在這種情況下，對於接受者而言，實物移轉就相當於現金，因為他們可以減少購買該項物品的支出，並將這筆錢用在其他地方。因此，這種類型的實物移轉對消費行為的影響與等值的現金移轉沒有差別。只有在實物移轉的量超過接受者在沒有該移轉但擁有等值現金時會消費的量時，實物移轉才會對消費行為產生影響，也就是扭曲消費行為。具體而言，假設政府每月發給一個家庭價值 100 元的白米飯，而這家庭本來每月會花 200 元買白米飯。這樣的話，這個家庭每月可以省下 100 元買米的錢，並且可以把這筆錢用在其他地方，而實物移轉與等值的現金移轉的效果就是相同的。\n2004 年，墨西哥的糧食援助計畫實驗（PAL）隨機將 208 個農村分為四組：實物移轉組（一組附加教育課程，一組沒有）、等值現金移轉組和無移轉的控制組。因為教育課程的提供和參與情況混亂，作者將這兩個實物轉移組別合併進行分析。被分到實物移轉組的家庭每個月可以得到十種常見食品的移轉，例如玉米粉、豆類、米、油和奶粉，市價約為 205 墨西哥披索。而被分到等值現金移轉組的家庭每個月可以得到 150 披索的現金，這是實物移轉的批發價格。\n研究發現，就整體食物消費而言，實物移轉與等值現金移轉的效果差不多，也就是說，家庭在收到等值的現金後，也會消費類似總量的食物。當然個別食品的消費可能有所不同，像是豆類和食用油（常買的食品），實物移轉不太造成扭曲，而像是奶粉和扁豆（不常買的食品），實物移轉會使得家庭消費更多。另外還有許多比較細節的結果，不過整體而言，雖然實物移轉確實改變消費行為、改善營養狀況，但是效果與等值的現金移轉差不多。作者並發現，領取現金移轉的貧困農村家庭不太會將大部分現金用於不良嗜好（如酒精、菸草和垃圾食品）。相反地，他們將大部分現金用於營養食品（如水果和蔬菜）、藥品和衛生用品。同時，把實物挪動到當地倉庫的配送成本大約佔實物批發價值的 20%。總之，至少在 PAL 計畫的情境中，似乎沒有什麼理由支持政府以家父長式的方式提供福利。\n\n\nLundborg, Rooth, and Alex-Petersen (2022)\n這篇文章發表在 RES，標題是 The Long-Term Effects of Childhood Nutrition: Evidence from a School Lunch Reform。作者評估 1959 年至 1969 年間在瑞典小學推行的免費營養午餐政策的長期效果。\n瑞典政府在小學引入免費營養午餐政策，為改善兒童營養攝入，並減輕家庭（尤其是母親）準備學童午餐的負擔，期望能提高女性勞動參與率並改善家庭經濟狀況。作者首先考察歷史資料，確定各地區何時引入免費營養午餐政策，再串聯多個行政資料與人口普查資料，估計政策對於學童的長期影響。研究結果顯示，這項學校午餐計畫有顯著的長期效益。在整個小學階段都接觸到該計畫的學生，其終身收入平均高出 3%。該計畫對早期接觸者和來自貧困家庭的學生影響更大，表示該計畫有助於縮小成年後的社會經濟不平等。接觸該計畫對教育程度和健康有所改善，而也提高母親的勞動參與率。\n計量上的問題我想到一些：\n\n讓我有趣的是，這並非 panel data，因為作者關心的是如終身收入等等的結果。經典的 DiD 要求 treated 和 control units 若無政策實施則有相同的時間趨勢。而這裡要求 treated 和 control group 若無政策實施則有相同的世代趨勢。但是，一個人只會屬於一個世代，這樣如何在個體層面定義 identification assumption？\n在建構樣本時，作者納入 1942 至 1965 年間出生在那 265 個在 1959 年後才實施免費營養午餐政策的地區的學童。此外，有 739 個地區在 1959 年前就已經實施免費營養午餐政策，因為作者不曉得這些地區的確切實施時間，所以這些地區的學童照理來說不在樣本中。但是，他仍然將這些地區 1959 年及之後開始上學的世代，他們聲稱，「因為知道他們在整個小學期間都接觸到了該政策，而這些學生對免費營養午餐的接觸沒有變異，納入他們又有助於估計世代效果」。我其實沒看懂「有助於估計世代效果」是什麼意思。如 Goodman-Bacon (2021) 那篇 JoE 所述，放入 always-treated 的樣本很可能會導致 negative weights。\n\n\n\nBraghieri, Levy, and Makarin (2022)\n這篇文章發在 AER，標題是 Social Media and Mental Health。作者利用 Facebook 在美國大學校園的逐步推出（staggered adoption）作為自然實驗，研究社交媒體使用對於心理健康的影響。\nFacebook 在 2004 年 2 月在哈佛大學上線，但遲至 2006 年 9 月才開放給一般大眾。在此期間，Facebook 逐步在美國大學校園推出。作者利用 Facebook 推出的時間差異與十七波的 NCHA 調查資料。研究發現，Facebook 的推出對學生心理健康有負面影響。接觸的時間越長，負面影響越大。作者認為，Facebook 等社群媒體平台讓使用者更容易與其他人比較。他們發現更可能遭受不利的社會比較的群體，其心理健康受 Facebook 推出的負面影響更大。\n計量上感覺沒什麼大問題。不過，在他的穩健性檢驗中，他提到 “to the extent that the trends are linear, we would be able to account for them in a robustness check that includes expansion-group-level linear time trends.” 我沒搞懂控制 linear time trends 具體解決的是什麼問題。我在網路上搜尋一番以後，發現原來指的是把時間當成一般的連續變數，而不是 dummies。而這個做法在 Mostly Harmless Econometrics 有提到（而且那頁我有畫記，顯然我應該讀過😅）。書上是這樣說的：\n\nAn alternative check on the DD identification strategy adds state-specific time trends to the list of controls. In other words, we estimate \\[\nY_{ist} = \\gamma_{0s} + \\gamma_{1s} t + \\lambda_t + \\delta D_{st} + X_{ist}' \\beta + \\varepsilon_{ist},\n\\] where \\(\\gamma_{0s}\\) is a state-specific intercept, as before, and \\(\\gamma_{1s}\\) is a state-specific trend coefficient multiplying the time trend variable, \\(t\\). […] As a rule, DD estimation with state-specific trends is likely to be more robust and convincing when the pretreatment data establish a clear trend that can be extrapolated into the posttreatment period.\n\n然後接著引用 Besley and Burgess (2004) 利用這個方法來做穩健性檢驗。我在網路上搜尋了一下，發現有人提到 Wolfers (2006) 討論到這個方法。\n\n\nWolfers (2006)\n這篇文章發表在 AER，標題是 Did Unilateral Divorce Laws Raise Divorce Rates? A Reconciliation and New Results。作者研究單方離婚法對離婚率的影響。\n1970 年代美國引入單方離婚法，允許在未經配偶同意的情況下尋求離婚。這時離婚率顯著上升。各界對此爭論紛紛。Leora Friedberg (1998) 分析離婚的行政資料，為了解決內生性問題，控制州與年的固定效果，與各州的時間趨勢。Friedberg 認為單方離婚法施行可以解釋自 1960 年代後期以來離婚率上升約六分之一的變異。一時之間，這個結論受廣泛接受。然而，Wolfers 認為 Friedberg 的結論有問題。\nWolfers 主張在做 DiD 的分析時，分辨既存的趨勢與政策衝擊的動態效果相當困難。他認為 Friedberg 控制各州的時間趨勢可能不只是消除掉既存的趨勢，還捕捉到政策效果。\n控制各州的時間趨勢以後，Friedberg 發現單方離婚法的係數大幅增加，Friedberg 認為這是遺漏變數偏誤。但是，Wolfers 質疑這個解釋。首先，會認為這是遺漏變數偏誤，就意味著 Friedberg 認為法律實施的時間點並非隨機的，各州是否及何時採用單方離婚法與各州的離婚率趨勢有關。進一步說，假如時間趨勢影響實施法律的時間點，那係數上升，也只能是「離婚率趨勢下降的州越可能採用單方離婚法」。但是，Wolfers 觀察到的趨勢卻是那些採用單方離婚法的州，實施前的離婚率趨勢相對於其他州略微增加。\nWolfers 認為離婚制度的變化可能有很不同的短期和長期效果。改革後，可能因為積壓的需求，離婚率可能會快速上升，經過複雜的動態變化，然後才逐漸趨於穩定。1 為了捕捉動態效果，Wolfers 估計以下的迴歸模型： \\[\n\\begin{aligned}\n\\mathit{Divorce\\;Rate}_{st}\n&= \\sum_{k \\geq 1} \\beta_k \\mathit{Unilateral\\;divorce\\;has\\;been\\;adopted}_{s,t} \\\\\n&\\quad + \\sum_{s} \\mathit{State\\;FE}_s + \\sum_{t} \\mathit{Time\\;FE}_t \\\\\n&\\quad + \\sum_{s} \\mathit{State}_s \\times Time_t +\n\\sum_{s} \\mathit{State}_s \\times Time_t^2 + \\varepsilon_{st}.\n\\end{aligned}\n\\] 但所以加入各州的線性和二次時間趨勢，到底是為了什麼？這樣的做法是否合理？我找了一陣子發現 Borusyak, Jaravel, and Spiess (2024) 的 RES 文章，Revisiting Event-Study Designs: Robust and Efficient Estimation，其中有一些理論的結果。因此這問題感覺沒有那麼值得現在深入研究。"
  },
  {
    "objectID": "posts/20250329-weekly-writing.html#其他",
    "href": "posts/20250329-weekly-writing.html#其他",
    "title": "週記（十）",
    "section": "其他",
    "text": "其他\n這週作息非常混亂。我很常弄到很晚才睡，因此白天精神不好。如此變成惡性循環。我對此有一些分析，但很懶得寫在這裡😔。"
  },
  {
    "objectID": "posts/20250329-weekly-writing.html#footnotes",
    "href": "posts/20250329-weekly-writing.html#footnotes",
    "title": "週記（十）",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nWolfers 這整段都是以文字描述，詳細我還得再想想。↩︎"
  },
  {
    "objectID": "misc/name-tag.html",
    "href": "misc/name-tag.html",
    "title": "名牌產生器",
    "section": "",
    "text": "這個產生器能讀 .tsv 檔。使用者需要把 .tsv 檔和 .tex 檔放在同個路徑之下。\n如果我們從 NTU COOL 上下載了學生名單，那我們可以用 R 把學生名單轉換成 .tsv 檔。注意這個 .tsv 檔要有兩個欄位，一個是中文名字 chinese，另一個是英文名字 english。\n\nlibrary(tidyverse)\nlibrary(readxl)\n\nfile_path &lt;- \"Student-List.xlsx\"\n\nstudent &lt;- read_excel(file_path) %&gt;%\n  mutate(\n    english = str_extract(Name, \"(?&lt;=\\\\().*(?=\\\\))\"),\n    chinese = str_remove(Name, \" \\\\(.*\")\n  )\n\nstudent %&gt;%\n  select(chinese, english) %&gt;%\n  write_tsv(\"student.tsv\")\n\n檔案大概要是長這樣。\nchinese english\n林一一  LIN, YI-Yi\n張二二 CHANG, ER-ER\n...\n再來就是 \\(\\rm \\LaTeX\\) 的部分。這個文件會讀取 .tsv 檔，然後把學生名字和學號印在 A4 紙上。注意這個文件要用 xelatex 編譯，因為我用了 xeCJK 套件來處理中文，而且要安裝相應的字型才能正常編譯（或者改成自己有的字型）。現在使用的幾個字型都是 overleaf 上有的。漢字字型是日文的 Harano Aji Gothic，因為有點缺字，所以缺字的地方會用 Noto Sans CJK JP 來代替。英文字型則是 IBM Plex Sans Condensed，會使用 Condesed 是因為這樣能塞下比較多的字，不至於把字縮得太小。\n\\documentclass[a4paper]{article}\n\\usepackage[margin=-10pt]{geometry}\n\\usepackage{fontspec}\n\\usepackage[AutoFallBack=true]{xeCJK}\n\\setCJKmainfont{Noto Sans CJK JP}\n\\setCJKsansfont[FallBack=Noto Sans CJK JP]{Harano Aji Gothic}\n\\setsansfont{IBM Plex Sans Condensed}\n\\usepackage{graphicx}\n\\pagestyle{empty}\n\\usepackage{csvsimple}\n\\usepackage{xcolor}\n\\definecolor{gray02}{gray}{0.2}\n\n\\newcommand{\\NamePlate}[2]{%\n  \\begin{center}\n    \\begin{tabular}{@{}c@{}}\n      %---------------------------------\n      % (1) 第一等分：空白\n      \\begin{minipage}[c][.25\\textheight][c]{.95\\textwidth}\n      \\end{minipage}\\\\\n      \\hline\n      %---------------------------------\n      % (2) 第二等分：旋轉 180° 的中英文姓名\n      \\begin{minipage}[c][.25\\textheight][c]{.95\\textwidth}\n        \\centering\n        \\rotatebox{180}{%\n          \\parbox{1\\textwidth}{\\centering\n            {\\fontsize{65}{72}\\selectfont\\sffamily\\bfseries\\textcolor{gray02}{#1}}\\\\[1cm]\n            {\\fontsize{60}{60}\\selectfont\\sffamily\\bfseries\\textcolor{gray02}{#2}}\n          }%\n        }\n      \\end{minipage}\\\\\n      \\hline\n      %---------------------------------\n      % (3) 第三等分：正常方向的中英文姓名\n      \\begin{minipage}[c][.25\\textheight][c]{.95\\textwidth}\n        \\centering\n        {\\fontsize{65}{72}\\selectfont\\sffamily\\bfseries\\textcolor{gray02}{#1}}\\\\[1cm]\n        {\\fontsize{60}{60}\\selectfont\\sffamily\\bfseries\\textcolor{gray02}{#2}}\n      \\end{minipage}\\\\\n      \\hline\n      %---------------------------------\n      % (4) 第四等分：空白\n      \\begin{minipage}[c][.25\\textheight][c]{.95\\textwidth}\n      \\end{minipage}\\\\\n    \\end{tabular}\n  \\end{center}\n}\n\n\\begin{document}\n\n\\csvreader[head to column names, separator=tab]{name_tab.tsv}{}{%\n   \\NamePlate{\\chinese}{\\english}\n}\n\n\\end{document}"
  },
  {
    "objectID": "misc/nutshell-model-selection.html",
    "href": "misc/nutshell-model-selection.html",
    "title": "Model Selection in Linear Regression",
    "section": "",
    "text": "We begin with a more general setup. Then, we will focus on the linear regression model.\nLet \\(X\\) be a \\(p\\)-dimensional predictor and \\(Y\\) be the outcome variable. We assume that the relationship between \\(X\\) and \\(Y\\) can be written as \\[\nY = f(X) + \\varepsilon,\n\\] where \\(f(X)\\) is the true conditional expectation function of \\(Y\\) given \\(X\\), and \\(\\varepsilon\\) is the error term with mean zero and variance \\(\\sigma^2\\). For example, in a linear regression model, we have \\[\nY = X^\\intercal \\beta + \\varepsilon,\n\\] where \\(\\beta\\) is the vector of coefficients.\nGiven a training set \\(\\mathcal{T} = \\left\\{x_i, y_i\\right\\}_{i = 1}^N\\), we estimate the conditional expectation function \\(f(X)\\) using a model \\(\\hat{f}(X)\\), which is a function of the training data \\(\\mathcal{T}\\). The loss function for measuring errors between \\(Y\\) and \\(\\hat{f}(X)\\) is denoted by \\(L(Y, \\hat{f}(X))\\).Typically, we use the squared error loss function: \\[\nL\\left(Y, \\hat{f}(X)\\right) = \\left(Y - \\hat{f}(X)\\right)^2.\n\\]"
  },
  {
    "objectID": "misc/nutshell-model-selection.html#the-setup",
    "href": "misc/nutshell-model-selection.html#the-setup",
    "title": "Model Selection in Linear Regression",
    "section": "",
    "text": "We begin with a more general setup. Then, we will focus on the linear regression model.\nLet \\(X\\) be a \\(p\\)-dimensional predictor and \\(Y\\) be the outcome variable. We assume that the relationship between \\(X\\) and \\(Y\\) can be written as \\[\nY = f(X) + \\varepsilon,\n\\] where \\(f(X)\\) is the true conditional expectation function of \\(Y\\) given \\(X\\), and \\(\\varepsilon\\) is the error term with mean zero and variance \\(\\sigma^2\\). For example, in a linear regression model, we have \\[\nY = X^\\intercal \\beta + \\varepsilon,\n\\] where \\(\\beta\\) is the vector of coefficients.\nGiven a training set \\(\\mathcal{T} = \\left\\{x_i, y_i\\right\\}_{i = 1}^N\\), we estimate the conditional expectation function \\(f(X)\\) using a model \\(\\hat{f}(X)\\), which is a function of the training data \\(\\mathcal{T}\\). The loss function for measuring errors between \\(Y\\) and \\(\\hat{f}(X)\\) is denoted by \\(L(Y, \\hat{f}(X))\\).Typically, we use the squared error loss function: \\[\nL\\left(Y, \\hat{f}(X)\\right) = \\left(Y - \\hat{f}(X)\\right)^2.\n\\]"
  },
  {
    "objectID": "misc/nutshell-model-selection.html#the-optimism",
    "href": "misc/nutshell-model-selection.html#the-optimism",
    "title": "Model Selection in Linear Regression",
    "section": "The Optimism",
    "text": "The Optimism\nThe test error, also known as the generalization error, is the prediction error of a model on a test sample. The test error of a model \\(\\hat{f}\\) is defined as \\[\n\\operatorname{Err}_{\\mathcal{T}} = \\operatorname{E}_{X^0, Y^0}\\left[ L \\left(Y^0, \\hat{f}\\left(X^0\\right)\\right) \\;\\middle|\\; \\mathcal{T} \\right],\n\\] where \\(\\left(X^0, Y^0 \\right)\\) is a new test data point. The test error measures how well the model generalizes to new data.\nThe expected test error is the average of the test errors over all possible training sets \\(\\mathcal{T}\\), \\[\n\\operatorname{Err} = \\operatorname{E}_{\\mathcal{T}} \\left[ \\operatorname{E}_{X^0, Y^0}\\left[ L \\left(Y^0, \\hat{f}\\left(X^0\\right)\\right) \\;\\middle|\\; \\mathcal{T} \\right] \\right].\n\\]\nThe expected test error at a point \\(x_0\\) is defined as \\[\n\\operatorname{Err}(x_0) = \\operatorname{E}\\left[ L \\left(Y, \\hat{f}\\left(x_0\\right)\\right) \\;\\middle|\\; X = x_0 \\right],\n\\] where \\(Y\\) is the outcome variable and \\(\\hat{f}(x_0)\\) is the predicted value at \\(x_0\\). The expected test error measures how well the model predicts the outcome variable at a specific point \\(x_0\\).\nThe in-sample error is the average of the expected test errors over the training data \\(\\mathcal{T}\\), \\[\n\\begin{aligned}\n\\operatorname{Err}_{in}\n&= \\frac{1}{N} \\sum_{i=1}^N \\operatorname{Err}(x_i) \\\\\n&= \\frac{1}{N} \\sum_{i=1}^N \\operatorname{E}_{Y^0}\\left[ L \\left(Y_i^0, \\hat{f}\\left(x_i\\right)\\right) \\;\\middle|\\; \\mathcal{T} \\right],\n\\end{aligned}\n\\] where \\(Y^0\\) notation indicates that we observe \\(N\\) new response values at each of the training points \\(x_i\\), \\(i = 1, 2, \\dots{}, N\\). We define the optimism as\nThe training error is the average loss over the training data \\(\\mathcal{T}\\), \\[\n\\overline{\\operatorname{err}}\n= \\frac{1}{N} \\sum_{i=1}^N L \\left(y_i, \\hat{f}\\left(x_i\\right)\\right).\n\\]"
  },
  {
    "objectID": "misc/nutshell-model-selection.html#the-bias-variance-decomposition",
    "href": "misc/nutshell-model-selection.html#the-bias-variance-decomposition",
    "title": "Model Selection in Linear Regression",
    "section": "The Bias-Variance Decomposition",
    "text": "The Bias-Variance Decomposition\nUnder the squared error loss function, the expected test error at a point \\(x_0\\) can be decomposed into three components: \\[\n\\begin{align*}\n&\\mathrel{\\phantom{=}} \\operatorname{Err}(x_0) \\\\\n&= \\operatorname{E}\\left[ \\left( Y - \\hat{f}(x_0) \\right)^2 \\;\\middle|\\; X = x_0 \\right] \\\\\n&= \\operatorname{E}\\left[ \\left( \\varepsilon + f(x_0) - \\hat{f}(x_0) \\right)^2 \\;\\middle|\\; X = x_0 \\right] \\\\\n&= \\sigma^2 + \\operatorname{E}\\left[\\left(f(x_0) - \\hat{f}(x_0) \\right)^2 \\;\\middle|\\; X = x_0 \\right] \\\\\n&= \\sigma^2 + \\left( f(x_0) - \\operatorname{E}  \\hat{f}(x_0) \\right)^2 + \\operatorname{Var}\\left( \\hat{f}(x_0) \\right) \\\\\n&=  \\sigma^2 + \\text{Bias}^2 + \\text{Variance},\n\\end{align*}\n\\] The first term \\(\\sigma^2\\) is the irreducible error, which is the variance of the error term \\(\\varepsilon\\). It cannot be avoided by any model. The second term is the squared bias, which measures how far the expected prediction \\(\\operatorname{E} \\hat{f}(x_0)\\) is from the true value \\(f(x_0)\\). The third term \\(\\operatorname{Var}\\left( \\hat{f}(x_0) \\right)\\) is the variance, which measures how much the predictions vary around their expected value.\nAlthough the true conditional expectation function \\(f(X)\\) may not be linear, we can still use a linear model to approximate it. Let \\(\\beta_*\\) be the linear projection coefficient of \\(Y\\) on \\(X\\); that is, \\[\n\\beta_* = \\operatorname*{argmin}_{\\beta} \\operatorname{E}\\left[ \\left( Y - X^\\intercal \\beta \\right)^2 \\right]\n= \\operatorname{E} \\left[X X^\\intercal \\right]^{-1} \\operatorname{E}\\left[ X Y \\right].\n\\] The ordinary least squares (OLS) estimator of \\(\\beta_*\\) is defined as the sample analogue of the above expression: \\[\n\\hat{\\beta} = \\left( \\sum_{i=1}^N X_i X_i^\\intercal \\right)^{-1} \\left( \\sum_{i=1}^N X_i Y_i \\right).\n\\] Then, the squared bias at \\(x_0\\) can be decomposed into two parts: \\[\n\\begin{aligned}\n&\\mathrel{\\phantom{=}} f(x_0) - \\operatorname{E} \\hat{f}(x_0) \\\\\n&= f(x_0) - \\operatorname{E} x_0^\\intercal \\hat{\\beta} \\\\\n&= \\left( f(x_0) - x_0^\\intercal \\beta_* \\right) + \\left( x_0^\\intercal \\beta_* - \\operatorname{E} x_0^\\intercal \\hat{\\beta} \\right).\n\\end{aligned}\n\\] The first term is called the model bias or specification bias, which measures how far the true conditional expectation function \\(f(x_0)\\) is from the linear projection \\(x_0^\\intercal \\beta_*\\). The second term is called the estimation bias, which measures how far the expected prediction \\(\\operatorname{E} x_0^\\intercal \\hat{\\beta}\\) is from the linear projection \\(x_0^\\intercal \\beta_*\\). Notice that the OLS estimator \\(\\hat{\\beta}\\) is an unbiased estimator of \\(\\beta_*\\), so the estimation bias is zero."
  },
  {
    "objectID": "misc/nutshell-model-selection.html#estimating-the-optimism",
    "href": "misc/nutshell-model-selection.html#estimating-the-optimism",
    "title": "Model Selection in Linear Regression",
    "section": "Estimating the Optimism",
    "text": "Estimating the Optimism\n\nMallows’ \\(C_p\\) Criterion\n\n\nAkaike Information Criterion (AIC)\n\n\nBayesian Information Criterion (BIC)"
  },
  {
    "objectID": "misc/nutshell-model-selection.html#leave-one-out-cross-validation-loocv",
    "href": "misc/nutshell-model-selection.html#leave-one-out-cross-validation-loocv",
    "title": "Model Selection in Linear Regression",
    "section": "Leave-One-Out Cross-Validation (LOOCV)",
    "text": "Leave-One-Out Cross-Validation (LOOCV)"
  },
  {
    "objectID": "misc/nutshell-iv.html",
    "href": "misc/nutshell-iv.html",
    "title": "Instrumental Variables in a Nutshell",
    "section": "",
    "text": "Suppose that the wage \\(Y_i\\) of individual \\(i\\) is linearly determined by education \\(D_i\\) (\\(1\\) if the individual has a college degree and \\(0\\) otherwise) and an unobservable ability \\(A_i\\): \\[\nY_i = \\beta_0 + \\beta_1 D_i + \\beta_2 A_i + e_i \\coloneqq \\beta_0 + \\beta_1 D_i + \\varepsilon_i,\n\\] where \\(D_i\\) and \\(A_i\\) are mean independent of \\(e_i\\), and \\(\\varepsilon_i \\coloneqq \\beta_2 A_i + e_i\\) is the structural error. We are interested in the causal effect of education \\(D_i\\) on wages \\(Y_i\\). This effect is given by \\(\\beta_1\\) in the DGP.1 If we can fit a linear regression of \\(Y_i\\) on \\(D_i\\) and \\(A_i\\), then the OLS estimator of \\(\\beta_1\\) is unbiased and consistent. However, what if we cannot observe \\(A_i\\)?\nThis scenario is known as omitted variable bias in traditional econometrics textbooks. The omitted variable bias arises when the unobservable \\(A_i\\) appears in the outcome equation and is correlated with \\(D_i\\). In this case, the OLS estimator of \\(\\beta_1\\) is biased and inconsistent: \\[\n\\frac{\\operatorname{Cov}(Y_i, D_i)}{\\operatorname{Var}(D_i)} = \\beta_1 + \\beta_2 \\frac{\\operatorname{Cov}(A_i, D_i)}{\\operatorname{Var}(D_i)}.\n\\]"
  },
  {
    "objectID": "misc/nutshell-iv.html#the-setup",
    "href": "misc/nutshell-iv.html#the-setup",
    "title": "Instrumental Variables in a Nutshell",
    "section": "",
    "text": "Suppose that the wage \\(Y_i\\) of individual \\(i\\) is linearly determined by education \\(D_i\\) (\\(1\\) if the individual has a college degree and \\(0\\) otherwise) and an unobservable ability \\(A_i\\): \\[\nY_i = \\beta_0 + \\beta_1 D_i + \\beta_2 A_i + e_i \\coloneqq \\beta_0 + \\beta_1 D_i + \\varepsilon_i,\n\\] where \\(D_i\\) and \\(A_i\\) are mean independent of \\(e_i\\), and \\(\\varepsilon_i \\coloneqq \\beta_2 A_i + e_i\\) is the structural error. We are interested in the causal effect of education \\(D_i\\) on wages \\(Y_i\\). This effect is given by \\(\\beta_1\\) in the DGP.1 If we can fit a linear regression of \\(Y_i\\) on \\(D_i\\) and \\(A_i\\), then the OLS estimator of \\(\\beta_1\\) is unbiased and consistent. However, what if we cannot observe \\(A_i\\)?\nThis scenario is known as omitted variable bias in traditional econometrics textbooks. The omitted variable bias arises when the unobservable \\(A_i\\) appears in the outcome equation and is correlated with \\(D_i\\). In this case, the OLS estimator of \\(\\beta_1\\) is biased and inconsistent: \\[\n\\frac{\\operatorname{Cov}(Y_i, D_i)}{\\operatorname{Var}(D_i)} = \\beta_1 + \\beta_2 \\frac{\\operatorname{Cov}(A_i, D_i)}{\\operatorname{Var}(D_i)}.\n\\]"
  },
  {
    "objectID": "misc/nutshell-iv.html#the-instrumental-variables-iv-estimation",
    "href": "misc/nutshell-iv.html#the-instrumental-variables-iv-estimation",
    "title": "Instrumental Variables in a Nutshell",
    "section": "The Instrumental Variables (IV) Estimation",
    "text": "The Instrumental Variables (IV) Estimation\nA solution to the omitted variable bias is to find an instrument \\(Z_i\\) satisfying two conditions:\n\nExogeneity: \\(\\operatorname{Cov}(Z_i, \\varepsilon_i) = 0\\).\nRelevance: \\(\\operatorname{Cov}(Z_i, D_i) \\neq 0\\).\n\nThe first condition ensures that the instrument \\(Z_i\\) is exogenous in the sense that it is uncorrelated with \\(\\varepsilon_i\\), the factors other than \\(D_i\\) that affect \\(Y_i\\). The second condition ensures that the instrument \\(Z_i\\) is correlated with \\(D_i\\).\nThe idea of IV estimation is that the effect of \\(D_i\\) on \\(Y_i\\) can be determined by the ratio of the effect of \\(Z_i\\) on \\(Y_i\\) to the effect of \\(Z_i\\) on \\(D_i\\).\nTo illustrate, suppose an increase of one unit in \\(Z_i\\) leads to an increase of \\(\\delta_1\\) units in \\(Y_i\\) and an increase of \\(\\pi_1\\) units in \\(D_i\\). Here, \\(\\delta_1\\) represents the effect of \\(Z_i\\) on \\(Y_i\\), and \\(\\pi_1\\) represents the effect of \\(Z_i\\) on \\(D_i\\). Given that \\(Z_i\\) only affects \\(Y_i\\) through \\(D_i\\), the effect of \\(D_i\\) on \\(Y_i\\), denoted by \\(\\beta_1\\), can be identified as the ratio \\(\\delta_1 / \\pi_1\\).\nFollowing this logic, the IV estimand is \\[\n\\begin{aligned}\n\\beta_{\\text{IV}}\n&\\coloneqq \\frac{\\operatorname{Cov}(Y_i, Z_i) / \\operatorname{Var}(Z_i)}{\\operatorname{Cov}D_i, Z_i) / \\operatorname{Var}(Z_i)} \\\\\n&= \\frac{\\operatorname{Cov}(\\beta_0 + \\beta_1 D_i + \\varepsilon_i, Z_i)}{\\operatorname{Cov}(D_i, Z_i)} \\\\\n&= \\beta_1 + \\frac{\\operatorname{Cov}(\\varepsilon_i, Z_i)}{\\operatorname{Cov}(D_i, Z_i)} \\\\\n&= \\beta_1.\n\\end{aligned}\n\\] Its sample counterpart is the IV estimator \\(\\hat{\\beta}_{\\text{IV}}\\): \\[\n\\hat{\\beta}_{\\text{IV}} \\coloneqq \\frac{\\sum_{i=1}^n (Y_i - \\bar{Y})(Z_i - \\bar{Z})}{\\sum_{i=1}^n (D_i - \\bar{D})(Z_i - \\bar{Z})}.\n\\] where \\(\\bar{Y}\\), \\(\\bar{D}\\), and \\(\\bar{Z}\\) are the sample means of \\(Y_i\\), \\(D_i\\), and \\(Z_i\\), respectively."
  },
  {
    "objectID": "misc/nutshell-iv.html#the-two-stage-least-squares-2sls-estimation",
    "href": "misc/nutshell-iv.html#the-two-stage-least-squares-2sls-estimation",
    "title": "Instrumental Variables in a Nutshell",
    "section": "The Two-Stage Least Squares (2SLS) Estimation",
    "text": "The Two-Stage Least Squares (2SLS) Estimation\nThe idea of 2SLS is to replace the endogenous regressor \\(D_i\\) with its fitted value from the first stage regression. The first stage regression is the regression of the endogenous regressor \\(D_i\\) on the instrument \\(Z_i\\). This works because the fitted value of \\(D_i\\) from the first stage regression contains only the variation in \\(D_i\\) that is explained by \\(Z_i\\) and is uncorrelated with the error term \\(\\varepsilon_i\\).\nLet the first stage population regression be \\[\nD_i = \\pi_0 + \\pi_1 Z_i + u_i,\n\\] where \\(u_i\\) is the projection error. The linear projection of \\(D_i\\) on \\(Z_i\\) is denoted by \\(\\mathscr{P}(D_i \\mid Z_i) = \\pi_0 + \\pi_1 Z_i\\). Then, the projection coefficient of \\(\\mathscr{P}(D_i \\mid Z_i)\\) in the regression of \\(Y_i\\) on \\(\\mathscr{P}(D_i \\mid Z_i)\\) is \\[\n\\begin{aligned}\n\\beta_{\\text{2SLS}}\n&= \\frac{\\operatorname{Cov}(Y_i, \\mathscr{P}(D_i \\mid Z_i))}{\\operatorname{Var}(\\mathscr{P}(D_i \\mid Z_i))} \\\\\n&= \\frac{\\operatorname{Cov}(\\beta_0 + \\beta_1 D_i + \\varepsilon_i, \\pi_0 + \\pi_1 Z_i)}{\\operatorname{Var}(\\pi_0 + \\pi_1 Z_i)}.\n\\end{aligned}\n\\] Substituting \\(D_i = \\pi_0 + \\pi_1 Z_i + u_i\\) into the above expression, we have \\[\n\\begin{aligned}\n\\beta_{\\text{2SLS}}\n&= \\frac{\\operatorname{Cov}(\\beta_0 + \\beta_1(\\pi_0 + \\pi_1 Z_i + u_i) + \\varepsilon_i, \\pi_0 + \\pi_1 Z_i)}{\\operatorname{Var}(\\pi_1 Z_i)} \\\\\n&= \\beta_1 + \\frac{\\operatorname{Cov}(\\beta_1 u_i + \\varepsilon_i, \\pi_1 Z_i)}{\\operatorname{Var}(\\pi_1 Z_i)} \\\\\n&= \\beta_1,\n\\end{aligned}\n\\] where the last equality follows from the fact that \\(Z_i\\) is uncorrelated with \\(u_i\\) by construction and is uncorrelated with \\(\\varepsilon_i\\) by the exogeneity assumption.\nIn practice, the 2SLS estimation is done in two stages.\n\nFirst stage: Regress \\(D_i\\) on \\(Z_i\\) to obtain the fitted value \\(\\hat{D}_i = \\hat{\\pi}_0 + \\hat{\\pi}_1 Z_i\\).\nSecond stage: Regress \\(Y_i\\) on \\(\\hat{D}_i\\), and the OLS estimator of the coefficient of \\(\\hat{D}_i\\) is the 2SLS estimator of \\(\\beta_1\\).\n\nImportantly, the 2SLS estimator is numerically equivalent to the IV estimator when there is only one endogenous regressor."
  },
  {
    "objectID": "misc/nutshell-iv.html#the-control-function-approach",
    "href": "misc/nutshell-iv.html#the-control-function-approach",
    "title": "Instrumental Variables in a Nutshell",
    "section": "The Control Function Approach",
    "text": "The Control Function Approach\nLike the 2SLS estimation, the control function approach also starts with the first stage regression of the endogenous regressor \\(D_i\\) on the instrument \\(Z_i\\). However, the control function approach differs from the 2SLS estimation in the second stage regression. Instead of regressing \\(Y_i\\) on the fitted value of \\(D_i\\), the control function approach regresses \\(Y_i\\) on \\(D_i\\) and the residuals \\(\\hat{u}_i\\) from the first stage regression.\nTo see why this works, note that the endogeneity problem arises because \\(D_i\\) is correlated with the error term \\(\\varepsilon_i\\). This correlation occurs because both \\(D_i\\) and \\(\\varepsilon_i\\) are affected by the unobserved ability \\(A_i\\). The key insight of the control function approach is that the first-stage residuals \\(u_i\\) capture the component of \\(D_i\\) that is correlated with \\(\\varepsilon_i\\). By including \\(u_i\\) as a control variable in the second stage regression, we “control for” the endogeneity.\nMore formally, let’s examine the relationship between \\(u_i\\) and \\(\\varepsilon_i\\). From the first stage regression, we have \\[\n\\begin{aligned}\nD_i &= \\pi_0 + \\pi_1 Z_i + u_i.\n\\end{aligned}\n\\] The residuals \\(u_i\\) represents the part of \\(D_i\\) that cannot be explained by \\(Z_i\\). Since \\(Z_i\\) is exogenous, this residual must capture all the endogenous variation in \\(D_i\\), including its correlation with \\(A_i\\). Therefore, \\(u_i\\) serves as a proxy for the unobserved ability \\(A_i\\) that’s causing the endogeneity problem.\nWhen we include \\(u_i\\) in the outcome equation, we have \\[\n\\begin{aligned}\nY_i &= \\beta_0 + \\beta_1 D_i + \\gamma u_i + \\eta_i,\n\\end{aligned}\n\\] where \\(\\eta_i\\) is the new error term that is uncorrelated with \\(D_i\\) and \\(u_i\\). The coefficient \\(\\gamma\\) captures the effect of \\(u_i\\) on \\(Y_i\\). The control function estimator \\(\\hat{\\beta}_{\\text{CF}}\\) is the OLS estimator of \\(\\beta_1\\) in the regression of \\(Y_i\\) on \\(D_i\\) and \\(u_i\\).\nAnother way to understand why the regression of \\(Y_i\\) on \\(D_i\\) and \\(u_i\\) identifies the causal effect of \\(D_i\\) on \\(Y_i\\) is to consider the population version of Frisch-Waugh-Lovell theorem. The projection coefficient of \\(D_i\\) in the regression of \\(Y_i\\) on \\(D_i\\) and \\(u_i\\) can be obtained by\n\nRegressing \\(D_i\\) on the first-stage residuals \\(u_i\\) to obtain residuals. The resulting residuals represent the component of \\(D_i\\) that is orthogonal to \\(u_i\\), which is precisely the linear projection of \\(D_i\\) on \\(Z_i\\), \\(\\mathscr{P}(D_i \\mid Z_i)\\).\nRegressing \\(Y_i\\) on \\(\\mathscr{P}(D_i \\mid Z_i)\\), and the coefficient of \\(\\mathscr{P}(D_i \\mid Z_i)\\) is \\(\\beta_1\\): \\[\n\\begin{aligned}\n\\beta_{\\text{CF}}\n&= \\frac{\\operatorname{Cov}(Y_i, \\mathscr{P}(D_i \\mid Z_i))}{\\operatorname{Var}(\\mathscr{P}(D_i \\mid Z_i))} \\\\\n&= \\frac{\\operatorname{Cov}(\\beta_0 + \\beta_1 D_i + \\varepsilon_i, \\pi_0 + \\pi_1 Z_i)}{\\operatorname{Var}(\\pi_0 + \\pi_1 Z_i)}.\n\\end{aligned}\n\\] Substituting \\(D_i = \\pi_0 + \\pi_1 Z_i + u_i\\) into the above expression as we did for the 2SLS estimation, we have \\[\n\\begin{aligned}\n\\beta_{\\text{CF}}\n&= \\beta_1 + \\frac{\\operatorname{Cov}(\\beta_1 u_i + \\varepsilon_i, \\pi_1 Z_i)}{\\operatorname{Var}(\\pi_1 Z_i)} \\\\\n&= \\beta_1,\n\\end{aligned}\n\\] where the last equality again follows from the fact that \\(Z_i\\) is uncorrelated with \\(u_i\\) by construction and is uncorrelated with \\(\\varepsilon_i\\) by the exogeneity assumption.\n\nIn practice, the control function approach is implemented as follows:\n\nFirst stage: Regress \\(D_i\\) on \\(Z_i\\) to obtain the residuals \\(\\hat{u}_i = D_i - \\hat{\\pi}_0 - \\hat{\\pi}_1 Z_i\\).\nSecond stage: Regress \\(Y_i\\) on \\(D_i\\) and \\(\\hat{u}_i\\), and the OLS estimator of the coefficient of \\(D_i\\) is the control function estimator of \\(\\beta_1\\).\n\nIt is clear that under linear models, the 2SLS and control function approaches are two sides of the same coin: they both exploit the first-stage regression, but the 2SLS approach replaces the endogenous regressor with its fitted value in the second stage, while the control function approach includes the residuals from the first stage as an additional control variable in the second stage."
  },
  {
    "objectID": "misc/nutshell-iv.html#footnotes",
    "href": "misc/nutshell-iv.html#footnotes",
    "title": "Instrumental Variables in a Nutshell",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nFor simplicity, we assume that there is no treatment effect heterogeneity. This means that the effect of education on wages is the same for all individuals. This assumption is already encoded in the structural equation above.↩︎"
  },
  {
    "objectID": "posts/20250201-weekly-writing.html",
    "href": "posts/20250201-weekly-writing.html",
    "title": "週記（二）",
    "section": "",
    "text": "自從上週六回家，每天都處在失眠—昏昏沈沈—失眠⋯⋯的惡性循環中。在家裏就覺得莫名的煩躁。回阿嬤家的話，這種煩躁程度大概還要乘以十倍。除了煩躁以外還覺得鬱悶。這讓我想到疫情的時候待在家裡的一段時間。只要待在家裡，就是幾乎整天都待在自己的房間內，意味著無法轉換環境以改變心情。在家無法分離工作和休閒。而且有燈光照明，氣溫穩定，幾乎沒有時間線索的環境，容易讓睡眠週期變調。1\n從我有記憶以來，我爸和我媽兩邊的祖父就已經過世了。所以兩邊他們都稱之為「○○○阿嬤家」，以地名區分（空格請填入地名）。小時候我很期待過年。因為平時太無聊了，只有過年才有機會見到年齡相近的堂表兄弟姊妹，而且我爸媽也很少帶我出門旅遊，幾乎只有過年能出門走走。小時候我們除夕會在我爸那邊的阿嬤家吃飯，初一會出門走春，初二回我媽那邊的阿嬤家，如此這般地消磨掉所有年假。\n隨著年紀越來越大，對我來說過年越來越沒有吸引力。可能是因為眼界開闊了，發現有趣的事情太多了。另一方面，阿嬤家的年味也越來越淡。自從我外婆過世以後，我媽那邊的親戚就不再初二相聚了；我祖母中風住院以後，我爸媽也似乎不覺得除了拜拜和吃飯以外，有必要再去阿嬤家。好在週日就回臺北。在臺北有好多事情要做。"
  },
  {
    "objectID": "posts/20250201-weekly-writing.html#過年",
    "href": "posts/20250201-weekly-writing.html#過年",
    "title": "週記（二）",
    "section": "",
    "text": "自從上週六回家，每天都處在失眠—昏昏沈沈—失眠⋯⋯的惡性循環中。在家裏就覺得莫名的煩躁。回阿嬤家的話，這種煩躁程度大概還要乘以十倍。除了煩躁以外還覺得鬱悶。這讓我想到疫情的時候待在家裡的一段時間。只要待在家裡，就是幾乎整天都待在自己的房間內，意味著無法轉換環境以改變心情。在家無法分離工作和休閒。而且有燈光照明，氣溫穩定，幾乎沒有時間線索的環境，容易讓睡眠週期變調。1\n從我有記憶以來，我爸和我媽兩邊的祖父就已經過世了。所以兩邊他們都稱之為「○○○阿嬤家」，以地名區分（空格請填入地名）。小時候我很期待過年。因為平時太無聊了，只有過年才有機會見到年齡相近的堂表兄弟姊妹，而且我爸媽也很少帶我出門旅遊，幾乎只有過年能出門走走。小時候我們除夕會在我爸那邊的阿嬤家吃飯，初一會出門走春，初二回我媽那邊的阿嬤家，如此這般地消磨掉所有年假。\n隨著年紀越來越大，對我來說過年越來越沒有吸引力。可能是因為眼界開闊了，發現有趣的事情太多了。另一方面，阿嬤家的年味也越來越淡。自從我外婆過世以後，我媽那邊的親戚就不再初二相聚了；我祖母中風住院以後，我爸媽也似乎不覺得除了拜拜和吃飯以外，有必要再去阿嬤家。好在週日就回臺北。在臺北有好多事情要做。"
  },
  {
    "objectID": "posts/20250201-weekly-writing.html#研究與閱讀",
    "href": "posts/20250201-weekly-writing.html#研究與閱讀",
    "title": "週記（二）",
    "section": "研究與閱讀",
    "text": "研究與閱讀\n為了尋找碩士論文題目（碩二下要開學了還沒確定題目😅），這週瀏覽了很多文章。經濟系的同學很容易在學校學到諸如 IV、DiD、RD 等等的研究設計，也就是 Mostly Harmless Econometrics 書裡提及的工具。可能在二十年前，學會這套工具就能夠發不錯的期刊（畢竟當時那本書都還沒寫出來呢），在十年前還能夠混口飯吃，但現在已經不夠了。希望開學前我能找到一些有趣的題目。\n這週開始讀兩本書，分別是 Steven Pinker 的 The Sense of Style 與陳瑞麟的《人類怎樣質問大自然》。我對 Pinker 的書比較感興趣。這本書臺灣也有翻譯，名為《寫作風格的意識》。雖然英文版用字遣詞不簡單（對我來說😔），但是我還是想先讀英文版，因為這是一本談英文寫作的書。我覺得有趣並期待的是，Pinker 作為一個鼎鼎大名的認知心理學家和語言學家，如何看待寫作。等到看完了以後再來分享閱讀心得。"
  },
  {
    "objectID": "posts/20250201-weekly-writing.html#其他",
    "href": "posts/20250201-weekly-writing.html#其他",
    "title": "週記（二）",
    "section": "其他",
    "text": "其他\n\n無聊的爭論\n話說前陣子 𝕏 上有一場辯論。有一個英國文學的教授稱，主流經濟學家都沒讀過 Adam Smith 和 Karl Marx，不知道自己學科發展的歷史，因此並非一個真正的領域（real discipline）。很多經濟學教授就受不了了，他們反駁說「因為經濟學不是一個讀老書就好的領域」或「你會要求科學家或工程師讀過牛頓的《自然哲學的數學原理》嗎？」等等。\n這個話題蠻沒營養的，引發爭議的英國文學教授的批評沒什麼道理，而那些對於這種沒什麼道理的批評感到不滿的經濟學教授也沒有必要這麼激動。但是還是有些重要的問題值得延伸。雖然這不影響經濟學作為一門學科的合法性，但回憶我求學的過程，確實很少人和我們提及歷史上那些偉大的經濟學家到底如何生產知識。許多課程一開始會簡單地介紹該領域的歷史，但通常是輝格式的，彷彿那些天才突然憑空想到這些精妙的理論。但科學的發展通常不是這樣的。改天有機會再寫寫這個話題。\n\n\n與學生的來往\n最近有個經原學生來信。他首先感謝我上學期提供的幫助，話鋒一轉，詢問我能否當他的家教，因為他想要準備經濟系的轉系考。\n轉系考我有經驗，但準備轉系考——我沒什麼經驗。2 畢竟我是助教，所以我回信婉拒他的家教邀請。但是還是分享了一些些我自己轉系的經驗。我對這個同學的印象蠻深刻的，他上學期曾經來信問我不少經原的問題。根據他的來信，我認為他很認真，甚至有點過於認真。會這麼說是因為，他會為了準備期考，練習非常多的考古題（久遠到可能是 KM 唸大學時的考古題）。因為考古題品質參差不齊，我認為這樣的練習方式不見得能見效，可能事半功倍。所以，我還向他分享了我認為更有效率的學習經原的方法（雖然也是一些老生常談）。3\n他後來又回覆我，告訴我自己為了轉系非常焦慮，上學期的成績並不是特別優異，而害怕失敗的焦慮感使他非常自責云云。\n我經常也有這樣的感受，即便我理性上知道沒有必要為了各種事情（包括但不限於課業）苛責自己，再苛責自己也不會讓情況好轉；我還知道，每個人的成長背景、天賦、優勢甚至運氣都不同，很多事情的結果取決於許多的因素，並不能完全歸咎於努力與否；我也知道陷在這種負面情緒中，反而會讓人更加裹足不前。我覺得自己知道，但是當我掉進負面情緒形成的漩渦時，腦袋裡頭還是只有各種負面的想法不斷盤旋，然後越來越陷入更深的焦慮。我覺得我大概是需要有人在我掉入那個漩渦時，真誠地提醒我不需要這樣。我自己其實很害怕求助，害怕造成別人的困擾，所以很少人能夠拉我一把。不過因為我知道或許我可以幫到他，所以我真的花了一段時間寫了一封長信。希望他能夠放輕鬆，不要太過焦慮，因為焦慮只會讓人更加焦慮。"
  },
  {
    "objectID": "posts/20250201-weekly-writing.html#footnotes",
    "href": "posts/20250201-weekly-writing.html#footnotes",
    "title": "週記（二）",
    "section": "Footnotes",
    "text": "Footnotes\n\n\n生物學家曾經做過實驗，讓受試者待在沒有光線、聲音與溫度變動的環境。當人失去環境給予的時間線索，睡眠—清醒週期會逐漸變成 25 個小時，於是與真實的日夜週期不協調。這裡偷了我自己 2021 年 6 月的臉書文的幾句話。↩︎\n我在上大學前的暑假修了經原，然後大一一整年幾乎沒什麼接觸經濟學，抱著「即使沒有成功轉系似乎也沒有關係」的心態去考試。所幸那次考試沒有那種很考驗記憶力的題目，於是我就成功轉系了。↩︎\n關於刷題與考試分數的關係，我最近看到一個有趣的比喻：【漫士】为什么做的题越多，考试反而越差？。↩︎"
  },
  {
    "objectID": "posts/20250222-weekly-writing.html",
    "href": "posts/20250222-weekly-writing.html",
    "title": "週記（五）",
    "section": "",
    "text": "這是我在臺大第十二個學期。從來沒有跨校選課，這是第一次，選了一門師大的書法課。\n週一下午兩點四十五分，我在住處附近買了一杯可不可，沿著和平東路，騎 YouBike 到師大。我想提前一些，避免找不到教室。這樣的擔心果然不是多餘的，我找了好一陣子，才找到教室。在抵達教室之前，我先去了和平 II 校區，後來才發現原來教室是在和平 I 校區。\n然後我穿過行政大樓——建築風格與臺大的相似——到了文學院。文學院給人一種擁擠的感覺。下課時間，幾乎每間教室門口都有人在等待。\n不過我也想到或許其實如駱明慶所說，是臺大社科院的教室太空。坐定位以後，我還是感覺蠻緊張的。我感覺自己像是重溫剛上大學的那種忐忑不安心情。希望能從這門課中學到一些東西。\n\n\n\nKM 覺得我可能對計量感興趣，上週便問我要不要和 JE 吃晚餐，時間是週四晚上。我答應了。不過，上週五 YC 打球受傷，因此 KM 說改在 YC 家吃晚餐。\n聽完 JE 的 CRETA seminar 以後，我們搭捷運到古亭站，然後 YC 的太太領我們到 YC 家。這時，YC 的爸媽正在準備晚餐。我一直都很不適應社交場合，這時候顯得更尷尬，只能尷尬地笑。\nYC 的媽媽廚藝不錯。不過也因為是 YC 的媽媽煮飯，我不好意思挑食，連番茄海鮮湯裡的洋蔥都吃了。他還炒了兩道青菜、切了一盤烏魚子，一盤馬鈴薯燉肉、還有一盤炒蝦。喝了一點點酒，最後還吃了冰淇淋。\n飯桌上大家都是有一搭沒一搭的開一些隨機的話題。畢竟平常也不是多常見面的人，有點考驗社交的能力（我完全沒有）。我記得上次跟 Alice 聊天後，KM 問我聊得如何，我說我常常不知道要跟他說什麼，有點尷尬。他說，聊天也是需要多練習的。大概是這樣吧。\nYC 的家庭應該不算是非常有錢，但生活還算是過得不錯。他們是外省人。據說，他媽媽的家庭到臺灣以前應該過得蠻舒適的，不過來臺灣就是什麼都沒帶，聽說在他媽媽出生前，長輩也把傭人都遣散了。有趣的是，他爸還說他媽媽的祖父（也就是 YC 的外曾祖父）臨終前還告訴兒女，「遲早要回大陸去的！」（當時兩岸還沒有交流）。\n此外，也就是隨機地見過幾次面，意想不到的是 YC 的爸媽對我這張臉還有印象。\n\n\n\n除了書法課，我還聽了一堂「統計管制與最佳化方法概論」。這門課對我來說太簡單了，因此我只是坐在教室裡頭，沒打算要選這門課。我猜這門課適合工學院，特別是工業工程領域，而對應用統計感興趣的人。\n我也去上統計所開的「統計學習」，老師教 Elements of Statistical Learning。沒意外的話我會修這門課。這門課似乎不是被定位成一門理論課，畢竟 ESL 的內容真的包山包海，要想教得深入真的很難。第一週老師就帶過了第一、二章，跳過第三章以後，開始講第四章。乍聽之下他講得蠻清楚的。只是 ESL 可以練習的東西真的很多，比如學習重製課本圖表之類的，感覺就要花不少時間。希望能拿捏好時間。"
  },
  {
    "objectID": "posts/20250222-weekly-writing.html#開學",
    "href": "posts/20250222-weekly-writing.html#開學",
    "title": "週記（五）",
    "section": "",
    "text": "這是我在臺大第十二個學期。從來沒有跨校選課，這是第一次，選了一門師大的書法課。\n週一下午兩點四十五分，我在住處附近買了一杯可不可，沿著和平東路，騎 YouBike 到師大。我想提前一些，避免找不到教室。這樣的擔心果然不是多餘的，我找了好一陣子，才找到教室。在抵達教室之前，我先去了和平 II 校區，後來才發現原來教室是在和平 I 校區。\n然後我穿過行政大樓——建築風格與臺大的相似——到了文學院。文學院給人一種擁擠的感覺。下課時間，幾乎每間教室門口都有人在等待。\n不過我也想到或許其實如駱明慶所說，是臺大社科院的教室太空。坐定位以後，我還是感覺蠻緊張的。我感覺自己像是重溫剛上大學的那種忐忑不安心情。希望能從這門課中學到一些東西。\n\n\n\nKM 覺得我可能對計量感興趣，上週便問我要不要和 JE 吃晚餐，時間是週四晚上。我答應了。不過，上週五 YC 打球受傷，因此 KM 說改在 YC 家吃晚餐。\n聽完 JE 的 CRETA seminar 以後，我們搭捷運到古亭站，然後 YC 的太太領我們到 YC 家。這時，YC 的爸媽正在準備晚餐。我一直都很不適應社交場合，這時候顯得更尷尬，只能尷尬地笑。\nYC 的媽媽廚藝不錯。不過也因為是 YC 的媽媽煮飯，我不好意思挑食，連番茄海鮮湯裡的洋蔥都吃了。他還炒了兩道青菜、切了一盤烏魚子，一盤馬鈴薯燉肉、還有一盤炒蝦。喝了一點點酒，最後還吃了冰淇淋。\n飯桌上大家都是有一搭沒一搭的開一些隨機的話題。畢竟平常也不是多常見面的人，有點考驗社交的能力（我完全沒有）。我記得上次跟 Alice 聊天後，KM 問我聊得如何，我說我常常不知道要跟他說什麼，有點尷尬。他說，聊天也是需要多練習的。大概是這樣吧。\nYC 的家庭應該不算是非常有錢，但生活還算是過得不錯。他們是外省人。據說，他媽媽的家庭到臺灣以前應該過得蠻舒適的，不過來臺灣就是什麼都沒帶，聽說在他媽媽出生前，長輩也把傭人都遣散了。有趣的是，他爸還說他媽媽的祖父（也就是 YC 的外曾祖父）臨終前還告訴兒女，「遲早要回大陸去的！」（當時兩岸還沒有交流）。\n此外，也就是隨機地見過幾次面，意想不到的是 YC 的爸媽對我這張臉還有印象。\n\n\n\n除了書法課，我還聽了一堂「統計管制與最佳化方法概論」。這門課對我來說太簡單了，因此我只是坐在教室裡頭，沒打算要選這門課。我猜這門課適合工學院，特別是工業工程領域，而對應用統計感興趣的人。\n我也去上統計所開的「統計學習」，老師教 Elements of Statistical Learning。沒意外的話我會修這門課。這門課似乎不是被定位成一門理論課，畢竟 ESL 的內容真的包山包海，要想教得深入真的很難。第一週老師就帶過了第一、二章，跳過第三章以後，開始講第四章。乍聽之下他講得蠻清楚的。只是 ESL 可以練習的東西真的很多，比如學習重製課本圖表之類的，感覺就要花不少時間。希望能拿捏好時間。"
  },
  {
    "objectID": "posts/20250222-weekly-writing.html#研究與閱讀",
    "href": "posts/20250222-weekly-writing.html#研究與閱讀",
    "title": "週記（五）",
    "section": "研究與閱讀",
    "text": "研究與閱讀\n這週去了一天半的衛福部：週三早上、週四早上、週五下午。開學以後的時間不得不分配得更緊湊、更零碎。沒什麼研究上的進展，也沒有讀書。要趕緊找到碩論題目，調整好步調，然後恢復閱讀。"
  },
  {
    "objectID": "posts/20250222-weekly-writing.html#其他",
    "href": "posts/20250222-weekly-writing.html#其他",
    "title": "週記（五）",
    "section": "其他",
    "text": "其他\n記錄一下新吃了什麼。\n週一吃了溫州街蘿蔔絲餅達人。這間似乎是名店，週一傍晚路過看到大排長龍，於是跟著排隊。我第一次吃蘿蔔絲餅，就是油炸的麵團包著蘿蔔絲。味道還可以，裡頭的蘿蔔絲很多，吃起來有點脆脆的，不過網路上也有人說他們不喜歡這樣偏生的口感。我倒是覺得還好。我還點了蔥油餅，同樣是油炸的。我比較喜歡蔥油餅。不知道是不是因為我放冷了才吃，感覺非常油，但蔥香味道還不錯。以價格和味道而言還不錯，是如果不用排太久的隊，而且吃垃圾食物的額度還沒用罄的時候會想吃的店。\n週六吃了 Boulangerie Ours，四維路上的歐式麵包店。我買了一根長棍、一個肉桂捲（sticky bun）、一個蘆筍培根佛卡夏和一塊巧克力餅乾。都很好吃。長棍外皮酥脆，內裡軟綿，味道不錯。肉桂捲的肉桂、堅果和焦糖味都很香。佛卡夏的蘆筍很鮮嫩，培根的鹹味和起司的香氣很搭。巧克力餅乾的巧克力味道很濃。下次還會再訪，試試看酸種和三明治。"
  },
  {
    "objectID": "posts/20250405-weekly-writing.html",
    "href": "posts/20250405-weekly-writing.html",
    "title": "週記（十一）",
    "section": "",
    "text": "書法課沒有上新的東西，因為下週要考試，因此這週稱為考前複習。\n統計學習課這週在教 model selection。老師不到三堂課就把 ESL 的第 7 章上完了。讀到現在我真不覺得 ESL 是一本適合入門統計學習或機器學習的書。有空的話或許應該也要去讀 Pattern Recognition and Machine Learning（PRML），這本書感覺更容易上手。說到 model selection，這個經濟系在計量課多少會教到一點點。不過我覺得大多數人的理解都很片面。改天來寫一篇短文介紹這邊的 big picture。"
  },
  {
    "objectID": "posts/20250405-weekly-writing.html#修課",
    "href": "posts/20250405-weekly-writing.html#修課",
    "title": "週記（十一）",
    "section": "",
    "text": "書法課沒有上新的東西，因為下週要考試，因此這週稱為考前複習。\n統計學習課這週在教 model selection。老師不到三堂課就把 ESL 的第 7 章上完了。讀到現在我真不覺得 ESL 是一本適合入門統計學習或機器學習的書。有空的話或許應該也要去讀 Pattern Recognition and Machine Learning（PRML），這本書感覺更容易上手。說到 model selection，這個經濟系在計量課多少會教到一點點。不過我覺得大多數人的理解都很片面。改天來寫一篇短文介紹這邊的 big picture。"
  },
  {
    "objectID": "posts/20250405-weekly-writing.html#研究與閱讀",
    "href": "posts/20250405-weekly-writing.html#研究與閱讀",
    "title": "週記（十一）",
    "section": "研究與閱讀",
    "text": "研究與閱讀\n這週只讀了一篇文章。\n\nArtmann, Oosterbeek, and van der Klaauw (2022)\n這篇文章發在 AEJ: Applied，標題是 Do Doctors Improve the Health Care of Their Parents? Evidence from Admission Lotteries。作者研究子女成為醫生是否會改善父母的健康照護和降低死亡率。\n民眾的醫療照護使用可能因為與健康無關的因素而存在差異，例如沒有充分的健康資訊、難以與醫療照護者溝通或者醫療照護的提供者可能差別對待不同背景的患者。作者注意到近期有一批文獻，透過比較醫生與其親屬與對照組，來研究以上這些原因的綜合影響。問題在於，醫生與其親屬這群人很可能與其他人很不一樣，以致我們不應該拿這群人與普羅大眾相比。那要如何研究健康資訊與近用對於健康照護的影響呢？\n荷蘭的大學原則上允許所有中學畢業生入學。然而，由於在 1960 年代末期，醫學院申請人數急劇增加，超過可用名額，因此引入了配額制度。在 1999 年之前，申請醫學院的學生需要參加抽籤，決定哪些學生可以進入醫學院，然後再將這些學生分配到荷蘭的八所醫學院。抽籤的權重依據學生中學畢業考試的 GPA 決定，學生會根據其 GPA 被劃分為不同的類別，每個類別在抽籤中擁有不同的權重。\n作者於是利用抽籤結果作為自然實驗，以申請醫學院的學生在第一次抽籤中獲得入學名額的機會作為工具變數，來研究子女成為醫生對父母健康照護的影響。本文的 structural equation 如下： \\[\nY_{it} = \\alpha_t + \\delta D_i + X_{i} \\beta + \\mathit{LC}_{i} + U_{it},\n\\] 其中 \\(Y_{it}\\) 是子女 \\(i\\) 的父母在時間 \\(t\\) 的結果變數，\\(D_i\\) 是子女 \\(i\\) 是否成為醫生的變數，而 \\(\\delta\\) 是作者感興趣的變數，\\(X_{i}\\) 是數個控制變數與固定效果，\\(\\mathit{LC}_{i}\\) 是子女 \\(i\\) 彩券類別和首次參與年份之間的交乘項（中籤機率完全取決於類別與參與年份），\\(\\alpha_t\\) 是時間固定效果。\n作者發現子女成為醫師對父母死亡率的因果效應接近於零，且統計上不顯著；對於其父母多數的醫療照護利用變數的影響在統計上也不顯著。作者認為至少在荷蘭的情境中，透過身為醫生的子女而獲得醫療專業知識和服務，並非造成父母醫療照護利用和死亡率差異的重要原因。\n這篇文章在計量上沒什麼創舉（通常那些說自己使用 novel identification strategy 但沒有給出嚴謹的論證的東西感覺比較值得多想想），不過作者在 hazard rate 的分析只有跑 reduced-form 模型，他在腳注裡說工具變數法不太容易與非線性的 hazard rate 模型結合。不過我似乎感覺（雖然還未仔細研究過）這種情況下可以用 control function 的方法來處理。簡單來說，就是把 first stage residuals 加進 second stage 的模型裡，以當作 unobserved confounders 的代理變數。我後來查了一下在存活分析中確實有這樣一招，就稱為 two-stage residual inclusion (2SRI)。"
  },
  {
    "objectID": "posts/20250405-weekly-writing.html#其他",
    "href": "posts/20250405-weekly-writing.html#其他",
    "title": "週記（十一）",
    "section": "其他",
    "text": "其他\n這學期當 KM 的大二計量課助教。這學期的計量課用 Bruce Hansen 的課本（我也是看這本課本才真正入門計量的，因此我有買這本書！）。通常 Hansen 的課本會當作經濟系碩博班必修課的用書。所以這本書確實對大多數的大二學生來說比較難上手。為了讓學生知難而退，KM 在課程大綱中就提及這門課一週大約要花 20 小時，還考了期初考（平均 50 分）。可是不僅實體課堂的出席率不高，課程影片也沒什麼人在看，並除了 lab 的學生以外，很少人去他或助教的 office hour。因此，他上週發了一封信，名為 Volker shock，裡面講到 Fed 主席 Volker 在 1980 年代的時候，為了對抗通貨膨脹，將利率提高到 20%。這樣的做法造成很大的衝擊，但也讓通貨膨脹回落。KM 說必要的話他也會這樣做。\n結果這封信引起軒然大波，有一篇相關的討論文章，甚至一度成為 Dcard 臺大板的熱門文章。文章的作者覺得自己絕對不是不用功的學生，但是老師的教學品質非常差。當然留言區就是正反意見都有。後來 KM 也找我們簡單地開了個會。他說他心目中的模範就是他當年修的陳金次的高等微積分。這門課的負擔他估計大約是當時那門高微的 70%。他並堅持不會修改教學目標和要求。因為他希望這對來年的學生是個有效地訊號。那些想要一週花 20 小時學 Hansen 的才會來他的班。我覺得挺有趣的。不知道我會不會有機會當老師，也不知道屆時應該如何教學生、要求學生。\n\n努力想想除了工作、讀書和耍廢的時候在做些什麼。\n週一在住處自己煮了一些蔬菜和雞胸肉。最近覺得因為外食，自己真是吃太少蔬菜了。因此偶爾開始煮一些方便的蔬菜。\n週三和大學同學在忠孝復興站附近吃了烤魚、喝了雞湯，都還不錯。雞湯很適合獨食，是如果在附近不知道要吃什麼，會想去吃的餐廳。\n週四第一次去了遠企樓下的 city’Super，店內空間不大，但有很多舶來品。有空的話應該仔細逛逛。拿到了 F 的草莓蛋糕，好吃。\n週五去了好久沒去的未央。上次去可能是大四吧，熬夜準備線性代數的期考（結果考很爛😭）。蜂蜜柚子茶有點太甜。莓果蛋白餅好吃，但餅乾本人有點像是比較脆的旺仔小饅頭。\n週六練了一晚上的書法。"
  },
  {
    "objectID": "posts/20250322-weekly-writing.html",
    "href": "posts/20250322-weekly-writing.html",
    "title": "週記（九）",
    "section": "",
    "text": "這週書法課終於開始寫字。\n這週沒去上統計學習課。原因見其他。"
  },
  {
    "objectID": "posts/20250322-weekly-writing.html#修課",
    "href": "posts/20250322-weekly-writing.html#修課",
    "title": "週記（九）",
    "section": "",
    "text": "這週書法課終於開始寫字。\n這週沒去上統計學習課。原因見其他。"
  },
  {
    "objectID": "posts/20250322-weekly-writing.html#研究與閱讀",
    "href": "posts/20250322-weekly-writing.html#研究與閱讀",
    "title": "週記（九）",
    "section": "研究與閱讀",
    "text": "研究與閱讀\n這週看了一些俗稱是 reduced-form 的應用個體文章。雖然我有發現一些問題，但多被做走了。不過 YC 似乎比較樂觀，他覺得有想到這些厲害的人做了的題目也不錯，可以用一張試算表把讀過的實證文章和相關的計量文章紀錄起來，再看要往下鑽研或者看看其他實證文章。真感謝他的鼓勵😔。\n\nLondoño-Vélez and Saravia (2025)\n這篇文章發表在 QJE，標題是 The Impact of Being Denied a Wanted Abortion on Women and Their Children。作者利用哥倫比亞的行政資料，研究拒絕墮胎對女性和她們的孩子的影響。\n哥倫比亞從 2006 年開始，將墮胎部分合法化，除了非自願的懷孕，只要醫師或心理師認為懷孕危及孕婦的物理、心理或社會健康，就可以合法墮胎。問題是，實際獲得合法墮胎服務仍然非常困難：除了各種行政障礙，醫療機構經常以宗教為由拒絕提供墮胎服務。因此，許多符合墮胎條件的女性被迫申請 tutela（一種憲法保護令），要求法院命令醫療系統尊重她們的合法權利。Tutela 依法會被隨機分配給法官，而作者發現雖然男女法官在各種 tutela 案件中的判決沒有顯著差別，但在墮胎案件中，女性法官更傾向支持女性的申請。既然承審法官的性別是 tutela 申請成功的最重要的預測因子，而法官性別又不透過判決結果以外的因素影響那些申請者，作者便利用法官的性別作為工具變數，估計被拒絕墮胎對女性和她們的孩子的影響。\n研究發現，被拒絕墮胎的女性更有可能生下孩子，相比未被拒絕的女性，他們生下孩子的機率增加 30.7%（相當於兩倍於未被拒絕的女性最後生下小孩的機率）。而且，由於 80% 尋求墮胎的女性在當時沒有孩子，拒絕墮胎會迫使許多女性過早成為母親。注意到即使被拒絕合法墮胎，許多女性仍然終止懷孕，這顯示非法墮胎盛行。但是，墮胎藥物 misoprostol 對於超過 14 週的懷孕無效，因此這些女性可能不得不訴諸其他更不安全的手段。而且，被拒絕墮胎使女性在 9 個月內死亡的可能性增加 2.5%，比未被拒絕的女性高出 161%。作者發現死亡率增加主要是由於敗血症和感染，這顯示拒絕合法墮胎的女性轉向其他（可能不安全的）墮胎方法，增加了致命感染的風險。作者最後檢視了被拒絕墮胎對孩子的影響，發現這些孩子在出生時體重較低，並且在 5 歲時更有可能死亡。\n作者還探討了被拒絕墮胎的長期效果。他們發現，被拒絕墮胎的女性更可能有孩子，且孩子數量更多，被拒絕墮胎除了影響何時生育，還影響是否生育以及生育多少孩子；並且，被拒絕墮胎的女性更可能與親戚同住，這可能是因為她們需要額外的照顧；此外，被拒絕墮胎的女性更可能成為單親母親或經歷離婚與分居。而且，被拒絕墮胎降低了獲得高中文憑的可能性，並顯著減少了女性的勞動力參與。作者並與經典的母職懲罰（motherhood penalty）文獻進行比較，發現「非自願」母職對就業的負面影響比「自願」母職更大。被拒絕墮胎還會使女性的家庭貧困惡化，讓他們更依賴社會福利。這種財務壓力還會對兒童產生連鎖反應。作者分析了 2317 名母親尋求墮胎前已出生的最小子女的資料發現，墮胎被拒絕顯著降低了這些孩子接受教育的比例，並顯著增加了孩子參與勞動市場的可能性，他們可能因為家庭經濟困難而不得不工作，而且雖然被拒絕墮胎的女性更可能成為家庭主婦，但這些孩子卻更常獨自在家。\n計量上我覺得沒有什麼很值得挑剔的點。這應該可以說是一個蠻乾淨的自然實驗。\n\n\nCard, Colella, and Lalive (2024)\n這篇文章發表在 RES，標題是 Gender Preferences in Job Vacancies and Workplace Gender Diversity。\n2005 年起，奧地利政府通知雇主和報紙，在招募員工時表明性別偏好（stated gender preferences, SGP’s）是違法的（當時已經違法二十年），並且會受到罰款處罰（2004 年新引入的規定）。僅僅一年時間，廣告中表明性別偏好的比例從 40% 降到 5%。作者利用這個規定的改變，研究了性別偏好對工作機會的影響。作者以這件事為自然實驗，串連招聘網站上的職缺資訊與行政資料，研究禁止性別偏好招募對僱用結果的影響。\n在 2005 年之前，大多數招募廣告中的性別偏好與目標職缺的工作場所中的主要性別相符。即使偏好與職業或工作場所的主要性別不同，帶有性別偏好的職缺也非常有可能（&gt; 90%）由偏好的性別的候選人填補，這表明 SGP 可以說是公司招聘意圖的強烈信號。作者這裡使用這項通知之前的招募廣告中的性別偏好來預測每一特定公司職缺的對性別的偏好。接著他們利用 2000–2010 年間的招募資料，以實際上究竟一職缺是否由女性填補為結果變數，以預測的性別偏好為處理變數，跑了一些 DiD 和 event-study 的分析。研究發現，2005 年的運動導致被預測為偏好男性的職缺中女性的招聘比例顯著增加，而被預測為女性偏好的職位空缺中男性的招聘比例同樣顯著增加。\n此事件似乎導致一些公司「改變了主意」——聘用了那些在運動前會因其明確的性別偏好而被篩選掉的工人。作者進一步根據預測的性別偏好與目標職業的主要性別是否一致來考察了異質性效果。對於大多數預測偏好與主要性別相符的職位空缺（刻板印象的偏好），該運動按預期發揮了作用，提高了非偏好性別的招聘率，並增加了目標職業和招聘工作場所的性別多樣性。對於那些預測偏好與主要性別相反的職位空缺，則降低了性別多樣性。作者發現，運動前最密集使用男性性別偏好的招募的公司在 2005 年後女性員工比例出現了系統性的增長，而最密集使用女性偏好的公司則在男性員工比例方面也同樣增長。最後，作者也發現，在最密集使用性別偏好的公司中，沒有發現對公司生存率、總就業人數或平均工資產生負面影響。\n這同樣是一篇非常 reduced-form 的文章，而且沒有什麼高大上的技巧，甚至可以說他的實證策略非常 old-fashioned。不過，我對實證策略的疑惑以下包括主要兩點：\n\n雖然這裡使用了類似 DiD 和 event-study 的方法，但背後的道理並不太像標準的 DiD 設計。這裡不太一樣。首先，一個職缺到底在沒有實施政策時會不會有 SGP，在政策實施後的時期是看不到的，因為政策使得幾乎所有職位不再提出 SGP。本文的研究對象經歷的是一個非突然的、非強制性的政策影響，且作者無法直接識別出哪些雇主在沒有政策的情況下仍然會使用性別偏好。作者因此需要預測到底一個職缺是否會要求 SGP，再把問題放在 2SLS 的框架之下。問題在於，他估計到的東西真的可以有因果詮釋嗎？作者似乎也沒有考慮 generated regressor 的問題。而雖然預測錯誤率不高，但還是有錯，那如何詮釋有錯誤分類的估計結果呢？\n其次，經典的 DiD 設計中，政策開始之前沒有任何人接觸到政策，而在政策開始之後，實驗組接受政策，而對照組不接受。所以在經典的 DiD 設計中，識別假設是平均而言對照組的趨勢（例如政策實施前後的工資差距）與實驗組沒有接受政策的趨勢相同。這裡的設計不太一樣。在政策開始之前，有一些職缺使用 SGP，而有一些公司不使用。在政策開始之後，所有職缺都不使用 SGP。如果我們把使用 SGP 的職缺當成實驗組，沒有的當成對照組的話，就相當於對照組在政策開始之前就已經接觸到政策了。這違反經典的 DiD 設計。我有找到 Tazhitdinova and Vazquez-Bare (2023) 的 NBER Working Paper，Difference-in-Differences with Unequal Baseline Treatment Status 討論類似的問題，之後可以研究看看。\n\n\n\nKuhn and Shen (2023)\n這篇文章發表在 AER，標題是 What Happens When Employers Can No Longer Discriminate in Job Ads?。同 Card, Colella, and Lalive (2024)，這篇文章也探討當雇主不再能在招聘廣告中明確提出性別要求時會發生什麼。\n作者利用一個中國的線上招聘平臺的內部資料。上發生的意外事件作為自然實驗。在該平台上，雇主明確的性別要求在一夜之間應政府要求被移除。研究人員得以比較在性別要求被移除前後，不同職位的申請者和成功應聘者的性別比例。作者使用 RD in time 與 DiD 兩種方法，發現沒有性別要求的廣告的工作在禁令前後沒有明顯變化；那些原先要求男性的工作，女性申請比例大幅上升，女性獲得回電比例也相應增加，而原先要求女性的工作，男性申請比例顯著提高，男性獲得回電比例也相應增加。作者並發現，禁令對所有職位的總申請數量沒有顯著的負面影響，甚至可能略有增加；申請的配對品質沒有顯著下降；申請獲得回電的可能性沒有顯著下降；而中性廣告數量增加，雇主也沒有明顯地轉向其他招聘平台。作者認為這是因為雇主的性別歧視是基於過時的刻板印象，但當禁令實施後，許多雇主發現他們原先期望以外的申請者也能勝任工作。\n我跟 RD in time 的設計不太熟悉，不過這篇文章也用很多 DiD，面對的問題與 Card, Colella, and Lalive (2024) 類似。\n\n\nDuflo (2001)\n這篇文章發表在 AER，標題是 Schooling and Labor Market Consequences of School Construction in Indonesia: Evidence from an Unusual Policy Experiment。這篇文章探討基礎建設投資（在此是興建學校）是否能提高教育程度，以及教育程度的提高是否能帶來更高的收入。\n印尼政府在 1973 至 1978 年間，展開有史以來最大規模的學校建設計畫。作者使用印尼的人口普查資料，將 1950 至 1972 年間出生的男性的教育與薪資資料與其出生地區的資料串連起來。作者定義實驗組那些在 1973 年至 1978 年間生長在經歷了更密集的學校建設的地區的人，而控制組則是在那些學校建設較少的地區出生的人。研究發現，計畫確實顯著提高了學生的教育程度，並且對後來的工資產生了正向影響。\n我看完 Card et al. (2024) 和 Kuhn and Shen (2023) 之後，想到這篇文章。我沒有看過，但在模糊的印象中，也採用類似的實證策略。具體來說，作者所謂「更密集的學校建設」，是把興建的學校數量對小孩數量跑迴歸以後殘差項為正的地區。通常，我們會期待政府之所以在某個地區興建更多學校，是因為那裡的就學率較低，或者學校太少，而這件事很自然地與教育年數本身和未來的收入有關。如此，這很可能並不滿足平行趨勢假設。這也是為何作者還控制了各種固定效果。\n除此之外，Duflo 的設計還有一些地方與經典的 DiD 設計相異：\n\n作者比較高計畫強度地區和低計畫強度的地區，但是低計畫強度地區並非完全沒有學校建設，而高計畫強度地區的學校建設強度也存在差異。他其實是把原本連續的變數變成了二分變數。\nDuflo 還用了 DiD esitmates 的比值來估計教育對收入的影響（學校數量 ➡️ 教育 ➡️ 收入）。這種 Wald estimator 在 Chaisemartin and D’Haultfoeuille (2018) 稱為 Wald-DiD，背後仰賴過強的識別假設。"
  },
  {
    "objectID": "posts/20250322-weekly-writing.html#其他",
    "href": "posts/20250322-weekly-writing.html#其他",
    "title": "週記（九）",
    "section": "其他",
    "text": "其他\n週三早上到衛褔部，發現被排了兩個半天的座位，不同電腦。我當時才意識到我原來是預約兩個半天。\n去衛福部分析資料需要事前預約，每次以半天為單位。當天早上（或者前一天晚上），衛福部的公務員或研究助理會安排座位，並把各案的實體硬碟塞進安排的座位的電腦裡。這樣，研究者就可以在衛福部的環境下分析資料，而不用把資料帶回家。\n以往即便是預約兩個半天，公務員也會把兩個半天的座位安排在同一臺電腦上。因為，這也省得他們要把硬碟換來換去。不曉得是哪個菜鳥公務員排的座位。這意味著我必須要上午簽到，並在下午前簽退，然後挪動到另一個座位，再簽到，最後再簽退。很不方便。我不死心，問了一下輪值的行政人員，他說「對，否則算是爽約。」1 我只好乖乖照辦。我下午 13:20 要交統計學習課的作業。我先問了學弟印作業了沒。本想如果他還沒印，那就請他幫我印順便幫我交，但他印了，我就打算還是自己去交作業。\n我在 12:10 暫時離開衛福部，步行到昆陽捷運站。這時我想著，好久沒騎 YouBike 了，不如就騎到學校。等我騎上腳踏車才想到，我的電腦檔案的雲端備份出了問題，作業檔案不完整，所以我又騎腳踏車折回衛福部上傳作業到雲端。完成下樓後，我竟然發現原本停在衛福部附近人行道的腳踏車不見了。我找了一圈，也沒有找到。我只好走到捷運站，搭捷運到學校。我因為各種事情耽擱了，交完作業後，直到 13:10 才要離開學校。這時候再走到科技大樓搭捷運來不及在 13:30 簽退，於是叫了 Uber 搭車回到衛福部。我遇到一個健談的司機。他問我什麼學校幾年級，又問我去衛福部做什麼，還分享自己跟藥檢局交手的經驗。我用一隻耳朵和半個腦袋陪他聊天，一邊想到底哪裡做錯了。這才發現，我可能太緊迫了，沒有仔細分析利弊再行動。我應該要在中午離開衛福部時就簽退才對，就不用急著趕回去了。\n隔天週四，我又到現場。慶幸的是有在附近找到昨天丟失的 YouBike。不知道是被偷騎走，或者被誰挪動。我把腳踏車騎去昆陽捷運站還，這時候顯示租借費用已經累積至 1510 元。於是我到永春的 YouBike 服務中心說這件事，服務人員說可以幫我打折到 70 元（大概是依據我週三撥給客服告知這件事時的通話記錄決定的停止計費時間）。"
  },
  {
    "objectID": "posts/20250322-weekly-writing.html#footnotes",
    "href": "posts/20250322-weekly-writing.html#footnotes",
    "title": "週記（九）",
    "section": "Footnotes",
    "text": "Footnotes\n\n\n如果爽約，該案號會遭受輕微的懲罰，並且會有通知信寄到計畫主持人，也就是 KM 的信箱，然後我就會被 KM 關切。↩︎"
  },
  {
    "objectID": "posts/20250208-weekly-writing.html",
    "href": "posts/20250208-weekly-writing.html",
    "title": "週記（三）",
    "section": "",
    "text": "從小就反覆地受脂漏性皮膚炎困擾，症狀包括臉、頭皮、胸口會大面積地泛紅、脫屑。每當壓力大、心情糟糕時，總覺得特別嚴重。這週以惡劣的皮膚狀況開始。"
  },
  {
    "objectID": "posts/20250208-weekly-writing.html#阿里山",
    "href": "posts/20250208-weekly-writing.html#阿里山",
    "title": "週記（三）",
    "section": "阿里山",
    "text": "阿里山\n去年研究室就有人在喊著要出遊，但是一直沒有人想要排行程。有人曾經提過要去北海道、名古屋，都因此付諸東流。最後有同學願意帶大家去阿里山走眠月線，有同學要領著大家到東埔山莊附近看星星，有同學樂意開車載大家，才終於成行。據聞，KM 和開車的同學說，如果這臺車出車禍，臺灣經濟學界的研究進展會慢一年（哪有人會這樣說話😓）。\n週四一早我從住處附近搭公車到安和敦化路口，再從那裡搭公車到捷運長庚醫院站，離開車的同學家最近的捷運站。未料臺北市區早上交通壅塞，我稍微遲到一些。\n我們一路開車到臺中太平，接其中一位同學上車，並在太平吃了午飯。1 然後到東埔山莊。東埔山莊是許多山友攀登玉山的前哨戰，提供上下通鋪的床位。在盥洗並用完晚餐之後，預期到清晨三點要起床看星星，晚上七點多我就鑽進被窩裡睡覺。但我發現我有點認床，輾轉反側一個多小時才慢慢睡著，但九點多又有人一直進進出出而醒來，又胡思亂想各種事情到午夜才睡著。\n我凌晨兩點多起床，與同學們一起到麟趾山上看星星。山上的視野很好，群山環繞。正好有一段時間萬里無雲，又沒有城市的光害，我們肉眼就能看到滿天繁星。雖然我不認得幾顆星，只能透過手機軟體勉強辨認，但有個曾是天文社的同學，為我們指點諸如黃道十二宮或春季大三角等亮星的位置。\n我們快五點時回到山莊，為了六點半的日出，我又躺回床上，但翻來覆去都沒有睡著。不幸的是我們沒有選擇走到麟趾山，而是沿著水里玉山線走到東埔山的登山口，那裏西側開放遼闊，但東側卻被玉山遮擋，並不適合看日出，於是日出計畫以失敗作結。\n八點從山莊退房以後，開車前往阿里山森林遊樂區。我們接著從阿里山車站搭小火車到沼平車站，然後步行到眠月線的入口。眠月線是阿里山鐵路的支線，早年用以運輸木材，現在已經停駛。我們從眠月線的起點，沿著鐵道，經過塔山車站，走到接近石猴車站的檢哨所後折返。其中，我覺得比較有趣的是第一明隧道的坍落處。這個隧道在 921 震災後興建，在 88 風災後崩塌，遊客必須抓著岩壁、踩著鋼筋，快速通過。二號隧道，路線中最長的一座隧道，中段也在 88 風災時崩塌，以致遊客只能踩著土石，小心地從隧道上方的一個小洞通過。眠月線行程幾乎佔去一整天。晚上到達嘉義市區，下榻飯店，吃了林聰明沙鍋魚頭。最後大家一起在飯店裡喝了點酒。\n一早在飯店吃了簡單的自助早餐。後來喝了 Supiido 咖啡，吃了黃記涼麵。然後同學將我載到嘉義車站，我便離開隊伍自己在市區閒晃去。我在車站附近吃了 SAGAS 拉麵。味道不錯，以雞清湯麵為主，據稱是網美店，就是有點貴。然後我到嘉義市立美術館，正逢林玉山特展。正愁自己看不太懂畫時，幸運地遇上館內導覽。導覽員熱情地介紹畫作的創作背景和繪畫技法，以及館舍建築的歷史與設計巧思。\n我從嘉義車站搭公車到新埤，預計轉乘另一部公車到高鐵站，卻因為公車誤點而沒搭上。我只好叫了 Uber，在路邊等車。這時有個阿a伯peh問我要不要站進他家的騎樓等車，才不會冷。另一個阿a桑sáng（似乎是他的太太）和我閒聊，問我是當地人嗎？從哪裡來？有看日出嗎？有去奮起湖嗎？還說他們嘉義人都去過阿里山。最後我和他說了再見，搭上 Uber，搭上高鐵，回到臺北。"
  },
  {
    "objectID": "posts/20250208-weekly-writing.html#研究與閱讀",
    "href": "posts/20250208-weekly-writing.html#研究與閱讀",
    "title": "週記（三）",
    "section": "研究與閱讀",
    "text": "研究與閱讀\n週二 Meeting 以後，KM 主動問我碩論的狀況。據他的說法，他是想給我精神喊話。他首先關心我碩論要做什麼主題，並說如果要做 applied 的題目的話可以跟他，如果要做 treatment effects 的題目可以找 YC 或 YC。2 他認為碩論到底寫得如何其實不是什麼大事，重點是之後的 placement 如何。剛好我本就想找第二個 YC 聊聊，已經約了當天下午見面。當天 YC 和我說，他不缺兼任 RA，也因為不在臺大任職，不能指導我。他認為我最重要的事是完成碩論。他建議如果我想做 treatment effects 的題目，可以先找第一個 YC。他也說如果有需要而且指導教授同意的話可以與他聊聊。我下週應該要問問看第一個 YC。要趕緊決定碩論題目才行。\n這週三去了一整天的衛福部。重新整理了之前的程式。下週一還得再去。😔"
  },
  {
    "objectID": "posts/20250208-weekly-writing.html#footnotes",
    "href": "posts/20250208-weekly-writing.html#footnotes",
    "title": "週記（三）",
    "section": "Footnotes",
    "text": "Footnotes\n\n\n太平物價真的便宜，我點了 60 元的櫛瓜，原本預期就是幾片圓切，結果上了大半條的大櫛瓜。↩︎\n剛好這兩個人的名字簡稱都是 YC。↩︎"
  },
  {
    "objectID": "posts/20250308-weekly-writing.html",
    "href": "posts/20250308-weekly-writing.html",
    "title": "週記（七）",
    "section": "",
    "text": "不知道要寫什麼，來寫上課學到什麼好了。在此之前補述一下上週的學習。\n\n\n書法課分初學與進階兩組。這與練習的材料和評分標準有關。雖然我學了一陣子了，但還是沒把握自己能算是進階組，所以選了初學組。我修的這門課教智永的真書千字文。所謂真書，就是楷書的意思。當然在那個時代（隋朝），因為楷書似乎還沒有發展得那麼成熟（？），所以智永的楷書也帶有一點點行書的筆意。上週初學組從基本筆畫點、撇開始。\n至於統計學習，上課進度真的很快。上週老師教了 ESL 的第四章。第四章的主題是用於分類的線性方法。所謂線性方法，指的是那些判別函數 \\(\\delta_k(x)\\) 或後驗機率 \\(P(G = k \\mid X = x)\\) 模型（在單調轉換後）是線性的方法。\n具體而言，這章節最主要介紹 linear discriminant analysis (LDA) 和 logistic regression，與他們的一些變形。有趣的是 LDA 和 logistic regression 其實可以導出等價的判別準則，可是 LDA 卻需要假設資料從常態分配中抽出。這使 logistic regression 在理論上更穩健，而當資料真的從常態分配生成時，LDA 的漸進效率更好。另一件有趣的事情是 LDA 與線性迴歸有一個比較深的連結；課本習題 4.2 讓我們逐步推導，在二元分類問題中，如果兩類別的樣本數相當，那線性迴歸的決策邊界其實就是 LDA 的決策邊界。不過我還沒有參透背後的直觀意義。除此之外，最後還提了一點基於 separating hyperplanes 的分類方法，如 perceptron learning algorithm，然後為 support vector machine (SVM) 鋪路。\n\n\n\n這週書法課讓我們練習橫畫。不過，我當然已經很會了。就這樣沒什麼壓力地度過兩節課。\n這週的統計學習教 ESL 第五章的前半。第五章的內容是 basis expansions 和 regularization。我們這週就教各種 splines。我有感覺老師因為感覺自己上太快，所以刻意放慢速度。至於，有什麼有趣的東西嗎？我覺得課本習題 5.7，說 knots 在資料點 \\(x_i\\) 上的 natrual cubic splines 可以最小化 \\[\n\\operatorname{RSS}(f, \\lambda)\n= \\sum_{i=1}^N \\left( y_i - f(x_i) \\right)^2 + \\lambda \\int f''(t)^2 \\, dt\n\\] 這個目標函數，是一件很有趣的事情。不過講 smoothing splines 的計算時介紹到 B-splines，我真的是對這部分感覺很陌生。有時間應該好好研究研究😅。"
  },
  {
    "objectID": "posts/20250308-weekly-writing.html#修課",
    "href": "posts/20250308-weekly-writing.html#修課",
    "title": "週記（七）",
    "section": "",
    "text": "不知道要寫什麼，來寫上課學到什麼好了。在此之前補述一下上週的學習。\n\n\n書法課分初學與進階兩組。這與練習的材料和評分標準有關。雖然我學了一陣子了，但還是沒把握自己能算是進階組，所以選了初學組。我修的這門課教智永的真書千字文。所謂真書，就是楷書的意思。當然在那個時代（隋朝），因為楷書似乎還沒有發展得那麼成熟（？），所以智永的楷書也帶有一點點行書的筆意。上週初學組從基本筆畫點、撇開始。\n至於統計學習，上課進度真的很快。上週老師教了 ESL 的第四章。第四章的主題是用於分類的線性方法。所謂線性方法，指的是那些判別函數 \\(\\delta_k(x)\\) 或後驗機率 \\(P(G = k \\mid X = x)\\) 模型（在單調轉換後）是線性的方法。\n具體而言，這章節最主要介紹 linear discriminant analysis (LDA) 和 logistic regression，與他們的一些變形。有趣的是 LDA 和 logistic regression 其實可以導出等價的判別準則，可是 LDA 卻需要假設資料從常態分配中抽出。這使 logistic regression 在理論上更穩健，而當資料真的從常態分配生成時，LDA 的漸進效率更好。另一件有趣的事情是 LDA 與線性迴歸有一個比較深的連結；課本習題 4.2 讓我們逐步推導，在二元分類問題中，如果兩類別的樣本數相當，那線性迴歸的決策邊界其實就是 LDA 的決策邊界。不過我還沒有參透背後的直觀意義。除此之外，最後還提了一點基於 separating hyperplanes 的分類方法，如 perceptron learning algorithm，然後為 support vector machine (SVM) 鋪路。\n\n\n\n這週書法課讓我們練習橫畫。不過，我當然已經很會了。就這樣沒什麼壓力地度過兩節課。\n這週的統計學習教 ESL 第五章的前半。第五章的內容是 basis expansions 和 regularization。我們這週就教各種 splines。我有感覺老師因為感覺自己上太快，所以刻意放慢速度。至於，有什麼有趣的東西嗎？我覺得課本習題 5.7，說 knots 在資料點 \\(x_i\\) 上的 natrual cubic splines 可以最小化 \\[\n\\operatorname{RSS}(f, \\lambda)\n= \\sum_{i=1}^N \\left( y_i - f(x_i) \\right)^2 + \\lambda \\int f''(t)^2 \\, dt\n\\] 這個目標函數，是一件很有趣的事情。不過講 smoothing splines 的計算時介紹到 B-splines，我真的是對這部分感覺很陌生。有時間應該好好研究研究😅。"
  },
  {
    "objectID": "posts/20250308-weekly-writing.html#研究與閱讀",
    "href": "posts/20250308-weekly-writing.html#研究與閱讀",
    "title": "週記（七）",
    "section": "研究與閱讀",
    "text": "研究與閱讀\n又是碩論毫無進展的一週。還沒拿定主意要做什麼。來說一下我到底是對什麼有興趣。\n我想要做好的應用個體。我不認爲我會、我有能力或我想成為一個純粹的 econometric theorist。與其說我對計量經濟學有興趣，更貼切的說法是，我在從事經驗研究的過程中，產生一些困惑。我發現其中有些困惑曾經被一些人，例如計量經濟學家、其他科學領域的學者或者科學哲學家詢問、嘗試解答過。我實在很著迷於這些根本的科學方法論問題。一個最簡單、最普遍的疑問是，什麼時候我們會說 \\(X\\) 對 \\(Y\\) 有因果關係？（這不是一個簡單的問題）。然後我們還可以退一步問，這個問題是有意義的嗎？\n回到正題，如果要在經濟系做一些相關的研究，最直接地就是我去做一些計量經濟學的方法研究。現在我有一些感興趣的關鍵字：\n\n我對 difference-in-differences (DiD) 比較熟悉，這是做實證研究的經濟學家非常常用的研究設計。問題在於，DiD 的 papers 真的汗牛充棟，我不知道我有可能做出什麼新的貢獻。\n我對 mediation analysis 有興趣但不熟悉，這並不是大多數經濟學家熟悉的東西，做這個的大多在流行病學、政治學等領域。我覺得這個領域有很多有趣的問題。其中之一，就是我們能不能放寬經典的 sequential ignorability 假設。我曾經在 JC 的機器學習課的期末報告，嘗試提出一個利用 parallel trends 假設來識別一些 mediation analysis 參數的想法（然後用 double ML 的方式估計）。這是一個 DiD 設計的應用。但是，後來我也有點難信服我下的 parallel trends 假設真的可能在現實世界成立。一個潛在的方向是去研究它的 empirical contents，如最近有文章在討論怎樣的 selection mechanism 會產生 parallel trends，但我對這方向很悲觀，我感覺我沒有能力，而且沒有好結果。另一個方向是往 principal stratification 的方向發展，可是這感覺最終又會太像某篇 JBES 的文章。\n我對 treatment heterogeneity 也有興趣。這是另一個很冷門的主題。學過因果推論 101 的人都聽過 effect heterogeneity，但 treatment heterogeneity 是另一個問題。在 Rubin causal model 裡，通常假設 stable unit treatment value assumption (SUTVA)。這個假設可以分成兩個部分，第一是沒有干擾（interference），也就是說，任何人的 treatment condition 都不會影響其他人的 outcome；第二是 treatment 沒有多個「版本」，也就是說，那些被劃分成有同樣的 treatment condition 的人，他們的 treatment condition 真的是一樣的。第二個部分比較微妙，經濟學的文獻也很少人研究，既有的討論大部分在流行病學的文獻裡。所謂沒有多個版本，其實是要求 treatment 有清楚的定義。以血壓為例，研究者可能想了解降低血壓對健康的效果，但是這個 treatment 有很多版本，比如藥物治療、手術治療、飲食治療等等。如果放在 Heckman 那套「思想實驗」的框架的話，沒有多個版本的要求事實上也可以看成要求研究者所觀察到的實驗組和對照組，真的與他心目中的思想實驗的參數有關。這個問題在經濟學中似乎比較少被詳細討論。比如，我們經常測量婚姻的效果、生育的效果，但是這些 treatment 的定義其實是很模糊的，很難想像真的滿足 SUTVA。而這些研究者心目中的思想實驗是什麼？要怎麼把問題定義清楚？"
  },
  {
    "objectID": "posts/20250308-weekly-writing.html#其他",
    "href": "posts/20250308-weekly-writing.html#其他",
    "title": "週記（七）",
    "section": "其他",
    "text": "其他\n週四吃了個有點貴的晚餐。現在已經覺得自己對吃東西沒有太大興趣了😅。並且體悟到節制應該是重要的美德。另外，我還是覺得我更適合一些比較接地氣的食物，例如泰米香的油爆草蝦、聚的北海道昆布湯或者雙月的蒜好好瘦肉湯。\n\n用 Claude 3.7 Sonnet 完成 Perceptron 演算法的互動式視覺化\n現在的 LLM 真的不錯用。我用它寫了一個 perceptron 演算法的互動式視覺化。這個視覺化是基於 SVG 的，我只有手動修改一些美感的部分。\nRosenblatt 的 perceptron 演算法是一個簡單的二元分類演算法。它的目標是找到一個 hyperplane，使得正類樣本（標籤為 \\(+1\\) 的那些）在 hyperplane 的一邊，負類樣本（標籤為 \\(-1\\) 的那些）在 hyperplane 的另一邊。這個 hyperplane 可以寫成 \\(\\beta_1^\\intercal x + \\beta_0 = 0\\) 或 \\(\\beta^\\intercal x^* = 0\\)，其中，\\(\\beta = (\\beta_1, \\beta_0)\\)，而 \\(\\beta_1\\) 是該 hyperplane 的法向量，\\(x^* = (x, 1)\\) 是樣本的擴增後的向量。\n那這個演算法實際上怎麼找到那個 hyperplane 呢？它使用一種隨機的梯度下降法。具體來說，對於一個被誤分類的樣本 \\(x_i^*\\)，我們更新 \\(\\beta\\) 的規則是 \\(\\beta_{\\text{new}} \\leftarrow \\beta_{\\text{old}} + y_i z_i\\)，其中 \\(y_i\\) 是樣本的標籤，\\(z_i = x_i^* / \\| x_i^* \\|\\) 是樣本的標準化向量。所以如果 \\(x_i^*\\) 是一個正類樣本，而使得 \\(\\beta_1^\\intercal x_i + \\beta_0 &lt; 0\\)，那麼我們就應該把 \\(\\beta\\) 向 \\(z_i\\) 的方向移動一些，使得 hyperplane 能夠正確分類這個樣本。相反地，如果 \\(x_i^*\\) 是一個負類樣本，而使得 \\(\\beta_1^\\intercal x_i + \\beta_0 &gt; 0\\)，那麼我們就應該把 \\(\\beta\\) 向 \\(z_i\\) 的反方向移動一些，使得 hyperplane 能夠正確分類這個樣本。如果資料是是線性可分的，這個演算法最後會收斂到一個能正確分類所有樣本的 hyperplane。\n\n  \n    \n  \n\n  \n    執行一步\n    自動運行\n    重置\n  \n\n  \n  \n  \n  \n  \n  \n  當前狀態\n  \n  \n  \n  \n    迭代次數：0\n    \\(\\beta\\)：(0.00, 0.00, 0.00)\n    \n      \n        選中的點：(, )；標籤：\n        標準化向量 \\(z\\)：(, , )\n      \n    \n  \n  \n  \n\n  \n  \n  \n  \n  \n  \n  演算法說明\n  \n  \n  \n  \n    紅色向量：\\(\\beta\\) 參數向量，決定決策邊界，垂直於決策邊界\n    藍色線：當前決策邊界\n    綠色點：正類樣本（\\(+1\\)）\n    紅色點：負類樣本（\\(-1\\)）\n    紫色虛線：標準化向量 \\(z\\) \n    更新規則：\\(\\beta_{\\text{new}} \\leftarrow \\beta_{\\text{old}} + y_i z_i\\)（其中 \\(y_i\\) 是點的標籤，\\(z_i\\)  是標準化向量）\n    虛線框：當前被誤分類的點"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "關於",
    "section": "",
    "text": "喜歡吉娃娃的人。"
  }
]